{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/evolnode.png\" width=\"800\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Evolution Node free you from coding and debugging, let LLM evolve your code for you.</em></p>\n",
    "</div>\n",
    "<div align=\"left\">\n",
    "<p><em>Bored of manual coding, a function? EvolNode let LLM automate function design and guide the evolution of it with genetic algorithm. A node here takes a task, input, and output, it uses either code or another LLM to complete the task, ensuring aligned input and output value types and ,.names.Fitness evaluation is done by running the function with a few specified test cases, the more diverse the test case, the better the evolution.\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaPrompt, PromptMode\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meoh_evolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvolNode\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Code + Compilor Task\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# node = EvolNode(mp, None, None)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Prompt + LLM Task\u001b[39;00m\n\u001b[1;32m     14\u001b[0m mp \u001b[38;5;241m=\u001b[39m MetaPrompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet the age of a celebrity.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_celeb_age\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m], PromptMode\u001b[38;5;241m.\u001b[39mPROMPT) \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaPlan, extract_json_from_text\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_execute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_func_code, call_func_prompt\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_openai_response \u001b[38;5;28;01mas\u001b[39;00m get_response\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Dict, List\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/llm.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01manthropic\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m oai_client \u001b[38;5;241m=\u001b[39m OpenAI()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_from_path\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/types/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_stream_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageStreamEvent \u001b[38;5;28;01mas\u001b[39;00m MessageStreamEvent\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool_use_block_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolUseBlockParam \u001b[38;5;28;01mas\u001b[39;00m ToolUseBlockParam\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_create_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageCreateParams \u001b[38;5;28;01mas\u001b[39;00m MessageCreateParams\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mraw_message_stop_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RawMessageStopEvent \u001b[38;5;28;01mas\u001b[39;00m RawMessageStopEvent\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mraw_message_delta_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RawMessageDeltaEvent \u001b[38;5;28;01mas\u001b[39;00m RawMessageDeltaEvent\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/types/message_create_params.py:23\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageParam\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessageCreateParamsBase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessageCreateParamsStreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m ]\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mMessageCreateParamsBase\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mTypedDict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRequired\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"The maximum number of tokens to generate before stopping.\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43;03m    Note that our models may stop _before_ reaching this maximum. This parameter\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43;03m    [models](https://docs.anthropic.com/en/docs/models-overview) for details.\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/typing_extensions.py:850\u001b[0m, in \u001b[0;36m_TypedDictMeta.__new__\u001b[0;34m(cls, name, bases, ns, total)\u001b[0m\n\u001b[1;32m    848\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypedDict(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mf0: t0, f1: t1, ...}); each t must be a type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TAKES_MODULE:\n\u001b[0;32m--> 850\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtp_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__module__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mown_annotations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    856\u001b[0m         n: typing\u001b[38;5;241m.\u001b[39m_type_check(tp, msg)\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    858\u001b[0m     }\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/typing_extensions.py:851\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    848\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypedDict(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mf0: t0, f1: t1, ...}); each t must be a type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TAKES_MODULE:\n\u001b[1;32m    850\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 851\u001b[0m         n: \u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtp_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__module__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    853\u001b[0m     }\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    856\u001b[0m         n: typing\u001b[38;5;241m.\u001b[39m_type_check(tp, msg)\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    858\u001b[0m     }\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:186\u001b[0m, in \u001b[0;36m_type_check\u001b[0;34m(arg, msg, is_argument, module, allow_special_forms)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_argument:\n\u001b[1;32m    184\u001b[0m         invalid_generic_forms \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (Final,)\n\u001b[0;32m--> 186\u001b[0m arg \u001b[38;5;241m=\u001b[39m \u001b[43m_type_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_special_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_special_forms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(arg, _GenericAlias) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         arg\u001b[38;5;241m.\u001b[39m__origin__ \u001b[38;5;129;01min\u001b[39;00m invalid_generic_forms):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid as type argument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:164\u001b[0m, in \u001b[0;36m_type_convert\u001b[0;34m(arg, module, allow_special_forms)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mForwardRef\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_special_forms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:857\u001b[0m, in \u001b[0;36mForwardRef.__init__\u001b[0;34m(self, arg, is_argument, module, is_class)\u001b[0m\n\u001b[1;32m    855\u001b[0m     arg_to_compile \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(arg_to_compile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<string>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward reference must be an expression -- got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# input_dict = {\"n\": 10}\n",
    "# reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # Evolution with guaranteed structural fitness\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "node = EvolNode(mp, None, None)\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "reasoning, code = node.evolve([input_dict], \"i1\", replace=True)\n",
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"1000\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaPrompt I1: \n",
      "Goal: Help me date Dilireba, I'm a white colar worker living on salary.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON-style plan represented as a Directed Acyclic Graph (DAG) to achieve the goal. Use creative topology in the DAG, include parallel tasks if required.\n",
      "\n",
      "The plan should include:\n",
      "\n",
      "- **Nodes**: Each node represents a key action or step and must contain the following attributes:\n",
      "  - `task`: Description of the task.\n",
      "  - `name`: Concise name used for the task function.\n",
      "  - `input`: The resources, information, or prerequisites needed to perform the action.\n",
      "  - `output`: The immediate result or outcome of the action.\n",
      "  - `target`: The purpose or goal that the action contributes to.\n",
      "  - `mode`: The execution mode for this task (\"CODE\" or \"PROMPT\").\n",
      "\n",
      "- **Edges**: Each edge represents a dependency or relationship between nodes, indicating that one step supports or leads to another.\n",
      "  - `source`: The `id` of the source node (the preceding action).\n",
      "  - `target`: The `id` of the target node (the subsequent action).\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"task\": \"Task 1\",\n",
      "      \"name\": \"task_1\"\n",
      "      \"input\": \"Inputs required for Action 1\",\n",
      "      \"output\": \"Outputs/result of Action 1\",\n",
      "      \"target\": \"Purpose of Action 1\"\n",
      "      \"mode\": \"CODE\"\n",
      "    },\n",
      "    {\n",
      "      \"task\": \"Task 2\",\n",
      "      \"name\": \"task_2\",\n",
      "      \"input\": \"Inputs required for Action 2\",\n",
      "      \"output\": \"Outputs/result of Action 2\",\n",
      "      \"target\": \"Purpose of Action 2\",\n",
      "      \"mode\": \"PROMPT\"\n",
      "    }\n",
      "    // Add more nodes as needed\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\n",
      "      \"source\": \"task_1\",\n",
      "      \"target\": \"task_2\"\n",
      "    }\n",
      "    // Add more edges as needed\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "print(\"MetaPrompt I1: \")\n",
    "print(prompt)\n",
    "\n",
    "from methods.llm import get_openai_response\n",
    "response = get_openai_response(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# from methods.meta_prompt import parse_json_from_response\n",
    "\n",
    "tactic = re.findall(r\"\\{(.*)\\}\", response, re.DOTALL)\n",
    "plan_dict = extract_json_from_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<methods.eoh_evolution.EvolNode at 0x2893758d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, MetaPlan, extract_json_from_text\n",
    "from methods.eoh_evolution import EvolNode\n",
    "from methods.llm import get_openai_response as get_response\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Collect MetaPrompt from parsed Plan-Graph Response\n",
    "meta_node_prompts = []\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(task=node.get(\"task\"),  func_name=node.get(\"name\"), input=node.get(\"input\"), output=node.get(\"output\"), mode=node.get(\"mode\").lower())\n",
    "    meta_node_prompts.append(node_prompt)\n",
    "    \n",
    "edges = plan_dict[\"edges\"]\n",
    "\n",
    "EvolNode(meta_prompt = node_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RepoRAG\n",
    "* Smooth Dependency Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already cloned, skipping cloning...\n"
     ]
    }
   ],
   "source": [
    "from tools.repo import *\n",
    "\n",
    "# (I). Pick top growing repo\n",
    "# fastest_repos = get_fastest_growing_repos(days_ago=14, top_n = 50, print=False)\n",
    "# repo_url = fastest_repos[0]['html_url']\n",
    "\n",
    "# (I). Build a GIF of file-dependency of a git repo\n",
    "repo_url = \"https://github.com/xjdr-alt/entropix.git\"\n",
    "temp_repo = \"entropix_repo\"\n",
    "\n",
    "# file_graph = create_gif_from_repo(repo_url, temp_repo, frame_count=60, fps = 10, output_name=\"entropix_repo_evolution\") # File-Level Dependency Graph (not that useful?)\n",
    "file_dag = build_file_level_dag(repo_url, temp_repo)\n",
    "# visualize_dag(file_dag) # Slot this image into LLM --> pick a relevant file to zoom in on\n",
    "\n",
    "# (II). Build function-level dependency graph of a module within the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already cloned, skipping cloning...\n",
      "  Number of objects in the subgraph: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "success: successfully compiled d2_output/dag.d2 to d2_output/dag.png in 259.380125ms\n"
     ]
    }
   ],
   "source": [
    "# Dependency Graph collects all the 'components' required to build the current file (i.e. all the imports) -- useful for minimal implementation and bottom-up understanding\n",
    "\n",
    "# repo DAG (files..) --> file DAG (functions..) --> function DAG (sub-functions ...) --> sub-function code-snippet\n",
    "\n",
    "file_dag = build_file_level_dag(repo_url, temp_repo) # repo-level dependency graph (DAG) over all files\n",
    "# visualize_dag(file_dag) # Slot this image into LLM --> pick a relevant file to zoom in on\n",
    "\n",
    "python_files = get_python_files(temp_repo) \n",
    "python_file = python_files[3] # Makeshift approch to get a 'selected' python file\n",
    "\n",
    "file_dag = build_cross_file_dag(temp_repo, python_file)\n",
    "# visualize_dag(file_dag) # Slot this image into LLM --> pick a relevant module to zoom in on \n",
    "\n",
    "module_names = get_modules_from_file_dag(file_dag)\n",
    "module_name = module_names[0] # Makeshift approach to select module from python file\n",
    "\n",
    "module_dag = extract_subgraph_dag(file_dag, module_name, depth=6)\n",
    "visualize_dag(module_dag) # Less informative already ...\n",
    "\n",
    "# function-level depedency graph (DAG) for every file in the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from typing import NamedTuple\\n\\nimport jax\\nimport jax.numpy as jnp\\n\\n\\nclass KVCache(NamedTuple):\\n  k: jax.Array\\n  v: jax.Array\\n\\n  @classmethod\\n  def new(cls, layers: int, bsz: int, max_seq_len: int, kv_heads: int, head_dim: int) -> 'KVCache':\\n    return cls(\\n        k=jnp.zeros((layers, bsz, max_seq_len, kv_heads, head_dim), dtype=jnp.bfloat16),\\n        v=jnp.zeros((layers, bsz, max_seq_len, kv_heads, head_dim), dtype=jnp.bfloat16)\\n    )\\n\\n  def update(self, xk: jax.Array, xv: jax.Array, layer_idx: int, cur_pos: int, n_rep: int):\\n    ck = jax.lax.dynamic_update_slice(self.k, jnp.bfloat16(xk[None, ...]), (layer_idx, 0, cur_pos, 0, 0))\\n    cv = jax.lax.dynamic_update_slice(self.v, jnp.bfloat16(xv[None, ...]), (layer_idx, 0, cur_pos, 0, 0))\\n    if cur_pos == 0:\\n      keys = jnp.repeat(xk, n_rep, axis=2)\\n      values = jnp.repeat(xv, n_rep, axis=2)\\n    else:\\n      keys = jnp.repeat(ck[layer_idx], n_rep, axis=2)\\n      values = jnp.repeat(cv[layer_idx], n_rep, axis=2)\\n\\n    return keys, values, KVCache(k=ck, v=cv)\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.repo import read_node_content\n",
    "read_node_content(module_dag['node1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number of objects in the subgraph: 15\n"
     ]
    }
   ],
   "source": [
    "# (II). Build function-level dependency graph of a module within the repo\n",
    "from tools.repo import *\n",
    "\n",
    "temp_repo = \"hdcnn\" # Contains an interesting new DL model architecture's implementation\n",
    "\n",
    "# def build_dag_from_file(repo_name, file_path):\n",
    "python_files = get_python_files(temp_repo) # get all python files \n",
    "\n",
    "start_file = python_files[0] # pick the first one for debugging purpose \n",
    "\n",
    "dag = build_cross_file_dag(temp_repo, start_file)\n",
    "\n",
    "name_map = {dag[k][\"name\"]: k for k in dag} # Map name to node-id for all nodes in the DAG\n",
    "\n",
    "pick_object = list(name_map.keys())[0] # pick the first object from 'start_file'\n",
    "\n",
    "sub_dag = extract_subgraph_dag(dag, name_map[pick_object], depth=6) # Extact depedency graph starting from pick_object\n",
    "\n",
    "sub_dag = decide_opacity_of_dag(sub_dag, progress=1.0, cap_node_number=30) # limit number of nodes for easy understanding\n",
    "\n",
    "# func_graph = create_evolution_gif(sub_dag, frame_count=60, fps=10) # Sick Animation once again ...\n",
    "# visualize_dag(sub_dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.llm import get_claude_response # <-- this is the LLM we will be using for summarization\n",
    "from tools.repo import bottom_up_summarization, save_dag_as_json\n",
    "\n",
    "summarized_dag = bottom_up_summarization(sub_dag, get_claude_response)\n",
    "\n",
    "file_path = save_dag_as_json(summarized_dag, temp_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.repo import load_dag \n",
    "\n",
    "file_path = \"sandbox/hdcnn_dag.json\"\n",
    "file_dag = load_dag(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "success: successfully compiled d2_output/dag.d2 to d2_output/dag.png in 546.389749ms\n"
     ]
    }
   ],
   "source": [
    "from tools.diagram import visualize_dag, file_to_preprocessed_img\n",
    "\n",
    "png_file_path = visualize_dag(file_dag, show=False)\n",
    "img_base64 = file_to_preprocessed_img(png_file_path) # ready for visual prompting with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_claude_response \n",
    "from tools.repo import get_navigate_prompt\n",
    "\n",
    "json_file_path = file_path\n",
    "user_question = \"Describe the structure of this file\"\n",
    "retrieved_info = \"\"\n",
    "dag = file_dag\n",
    "\n",
    "def strategic_respond(json_file_path: str, \n",
    "                      user_question: str,\n",
    "                      file_dag: dict):\n",
    "    \n",
    "    retrieved_info = \"\"\n",
    "    prompt = get_navigate_prompt(json_file_path, user_question, retrieved_info, file_dag)\n",
    "    \n",
    "\n",
    "\n",
    "    response = get_claude_response(prompt, img=img_base64, img_type=\"image/png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occam Razor: Code-Interpreter  + Dictionary Manipulation \n",
    "\n",
    "# Unify: When there is a code-snippet, compile and go to next step, otherwise directly use the response as answer ....\n",
    "\n",
    "from tools.interpreter import CodeInterpreter\n",
    "\n",
    "interpreter = CodeInterpreter() \n",
    "\n",
    "code_result, figure, has_code = interpreter(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDCNNClassifier (class):\n",
      "  Summary: This code defines a simple neural network classifier called HDCNNClassifier. It consists of two fully connected layers with a ReLU activation and dropout in between. The network takes high-dimensional input vectors and outputs class probabilities for multiple classes.\n",
      "  Dependencies: node18\n",
      "\n",
      "HDComputing (class):\n",
      "  Summary: This code defines a class `HDComputing` that implements core operations for hyperdimensional computing. It includes methods for generating random hypervectors, superposing (combining) multiple vectors, binding (associating) two vectors, and permuting (shifting) a vector. These operations are fundamental in hyperdimensional computing for creating and manipulating high-dimensional representations of data.\n",
      "  Dependencies: node9, node8, node11, node10\n",
      "\n",
      "AGNewsDataset (class):\n",
      "  Summary: This code defines a custom PyTorch Dataset class called AGNewsDataset for processing and encoding text data. It preprocesses text by tokenizing, removing stop words and punctuation, truncating to a maximum length, and adding special tokens. The processed tokens are then encoded into high-dimensional vectors using hyperdimensional computing techniques. The class provides methods to get the dataset length and retrieve encoded items with their labels.\n",
      "  Dependencies: node15, node3, node14\n",
      "\n",
      "main (function):\n",
      "  Summary: This code implements a text classification task using hyperdimensional computing (HD) and a neural network on the AG News dataset. It includes data preprocessing, vocabulary building, HD encoding, model training with early stopping, and evaluation. The program also implements a Naive Bayes classifier as a baseline for comparison.\n",
      "  Dependencies: node2, node4\n",
      "\n",
      "build_vocab (function):\n",
      "  Summary: This function builds a vocabulary from a dataset of text items. It tokenizes each text, removes non-alphabetic tokens and stop words, counts token frequencies, and creates a vocabulary dictionary with the most common tokens up to a specified maximum size. Special tokens are added at the beginning of the vocabulary.\n",
      "  Dependencies: \n",
      "\n",
      "create_token_hvs (function):\n",
      "  Summary: This function creates a dictionary of high-dimensional vectors (HVs) for a given vocabulary. Each token in the vocabulary is assigned a random HV generated using a hyperdimensional computing (HD) object. The function uses a dictionary comprehension to efficiently create this mapping.\n",
      "  Dependencies: \n",
      "\n",
      "encode_sequence (function):\n",
      "  Summary: This function encodes a sequence of tokens into a single high-dimensional vector (HV) using hyperdimensional computing techniques. It iterates through the tokens, retrieves their corresponding HVs, applies position-based permutations, and combines them using element-wise addition. The final result is binarized using the sign function.\n",
      "  Dependencies: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code_result)\n",
    "# figure\n",
    "# has_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BreakDown on Task (When something is hard, we break it down)\n",
    "\n",
    "# 1. Construct step-wise PNG\n",
    "#    - transparency changing function\n",
    "#    - growing strategy (code-based subnodes as importance score)\n",
    "# 2. Animate into GIF (not perfect due to scale disconnection)\n",
    "\n",
    "\n",
    "# 3. Agent to understand codebase with repo-DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
