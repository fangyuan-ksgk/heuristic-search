{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution Node \n",
    "- Task, Input, Output\n",
    "- LLM guided evolution\n",
    "- LLM-engineered Code Function or Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "node = EvolNode(mp, None, None)\n",
    "reasoning, code = node._evolve(\"i1\", replace=True)\n",
    "input_dict = {\"n\": 10}\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "# mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name_of_celebrity\"], [\"age\"], PromptMode.PROMPT) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# reasoning, code = node._evolve(\"i1\", replace=True)\n",
    "# node(\"Deilireba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fibonacci(n: int) -> list:\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    if n == 1:\n",
      "        return [0]\n",
      "    sequence = [0, 1]\n",
      "    while len(sequence) < n:\n",
      "        sequence.append(sequence[-1] + sequence[-2])\n",
      "    return sequence\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node(input_dict) # Ok we need a output dictionary here as well ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import List\n",
      "\n",
      "def fibonacci(n: int) -> List[int]:\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "\n",
      "    sequence = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        sequence.append(sequence[-1] + sequence[-2])\n",
      "    return sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'from typing import List\\n\\ndef fibonacci(n: int) -> List[int]:\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n\\n    sequence = [0, 1]\\n    for i in range(2, n):\\n        sequence.append(sequence[-1] + sequence[-2])\\n    return sequence'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(code)\n",
    "code = code.replace(\"import List\", \"from typing import List\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MetaPrompt' object has no attribute 'input_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_prompt \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39m_get_eval_prompt()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(eval_prompt)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_prompt.py:71\u001b[0m, in \u001b[0;36mMetaPrompt._get_eval_prompt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_eval_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    Asking for (input, output) pairs for evaluation\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     prompt_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     68\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the Python function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, generate 5 diverse (input, output) pairs for evaluation. \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     69\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThese pairs should cover different scenarios, including edge cases.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     70\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction signature:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m---> 71\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_hint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39minp,\u001b[38;5;250m \u001b[39mtype_hint\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_types))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     72\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide your response as a Python list of dictionaries. Each dictionary should have \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys. \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     73\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure that the types match the function signature.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     74\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample format:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     75\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     76\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     77\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_hint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inp, type_hint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_types)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m},\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     78\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{self.output_type}\u001b[39;00m\u001b[38;5;124m(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     79\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    },\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     80\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     81\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     82\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide 5 such pairs, ensuring type correctness and diversity in the inputs and outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m        \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt_content\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MetaPrompt' object has no attribute 'input_types'"
     ]
    }
   ],
   "source": [
    "eval_prompt = mp._get_eval_prompt()\n",
    "print(eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import List\n",
      "\n",
      "def fibonacci(n: int) -> List[int]:\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "    \n",
      "    sequence = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_value = sequence[-1] + sequence[-2]\n",
      "        sequence.append(next_value)\n",
      "    \n",
      "    return sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<code object <module> at 0x2abe81200, file \"<string>\", line 1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(code)\n",
    "\n",
    "from methods.meta_execute import compile_check\n",
    "compile_check(code)\n",
    "\n",
    "compile(code, '<string>', 'exec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution failed: No module named 'List'\n"
     ]
    }
   ],
   "source": [
    "def safe_exec(code_str, input_dict):\n",
    "    local_vars = {}\n",
    "    exec(code_str, {}, local_vars)\n",
    "    if 'fibonacci' in local_vars and callable(local_vars['fibonacci']):\n",
    "        return local_vars['fibonacci'](input_dict['n'])\n",
    "    else:\n",
    "        raise ValueError(\"Function 'fibonacci' not found or not callable\")\n",
    "\n",
    "# Test the function with sample input\n",
    "input_dict = {\"n\": 10}\n",
    "try:\n",
    "    result = safe_exec(code, input_dict)\n",
    "    print(f\"Execution successful! Result for n={input_dict['n']}: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Execution failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import List\n",
      "\n",
      "def fibonacci(n: int) -> List[int]:\n",
      "    sequence = []\n",
      "    if n <= 0:\n",
      "        return sequence\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    \n",
      "    sequence = [0, 1]\n",
      "    while len(sequence) < n:\n",
      "        sequence.append(sequence[-1] + sequence[-2])\n",
      "    \n",
      "    return sequence\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution Graph\n",
    "- Take care of connecting each components (unfolding dictionary object etc.)\n",
    "- Planning topology with evolution node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaPrompt I1: \n",
      "Goal: Help me date Dilireba, I'm a white colar worker living on salary.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON-style plan represented as a Directed Acyclic Graph (DAG) to achieve the goal. Use creative topology in the DAG, include parallel tasks if required.\n",
      "\n",
      "The plan should include:\n",
      "\n",
      "- **Nodes**: Each node represents a key action or step and must contain the following attributes:\n",
      "  - `task`: Description of the task.\n",
      "  - `name`: Concise name used for the task function.\n",
      "  - `input`: The resources, information, or prerequisites needed to perform the action.\n",
      "  - `output`: The immediate result or outcome of the action.\n",
      "  - `target`: The purpose or goal that the action contributes to.\n",
      "  - `mode`: The execution mode for this task (\"CODE\" or \"PROMPT\").\n",
      "\n",
      "- **Edges**: Each edge represents a dependency or relationship between nodes, indicating that one step supports or leads to another.\n",
      "  - `source`: The `id` of the source node (the preceding action).\n",
      "  - `target`: The `id` of the target node (the subsequent action).\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"task\": \"Task 1\",\n",
      "      \"name\": \"task_1\"\n",
      "      \"input\": \"Inputs required for Action 1\",\n",
      "      \"output\": \"Outputs/result of Action 1\",\n",
      "      \"target\": \"Purpose of Action 1\"\n",
      "      \"mode\": \"CODE\"\n",
      "    },\n",
      "    {\n",
      "      \"task\": \"Task 2\",\n",
      "      \"name\": \"task_2\",\n",
      "      \"input\": \"Inputs required for Action 2\",\n",
      "      \"output\": \"Outputs/result of Action 2\",\n",
      "      \"target\": \"Purpose of Action 2\",\n",
      "      \"mode\": \"PROMPT\"\n",
      "    }\n",
      "    // Add more nodes as needed\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\n",
      "      \"source\": \"task_1\",\n",
      "      \"target\": \"task_2\"\n",
      "    }\n",
      "    // Add more edges as needed\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "print(\"MetaPrompt I1: \")\n",
    "print(prompt)\n",
    "\n",
    "from methods.llm import get_openai_response\n",
    "response = get_openai_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# from methods.meta_prompt import parse_json_from_response\n",
    "\n",
    "tactic = re.findall(r\"\\{(.*)\\}\", response, re.DOTALL)\n",
    "plan_dict = extract_json_from_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<methods.eoh_evolution.EvolNode at 0x2893758d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, MetaPlan, extract_json_from_text\n",
    "from methods.eoh_evolution import EvolNode\n",
    "from methods.llm import get_openai_response as get_response\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Collect MetaPrompt from parsed Plan-Graph Response\n",
    "meta_node_prompts = []\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(task=node.get(\"task\"),  func_name=node.get(\"name\"), input=node.get(\"input\"), output=node.get(\"output\"), mode=node.get(\"mode\").lower())\n",
    "    meta_node_prompts.append(node_prompt)\n",
    "    \n",
    "edges = plan_dict[\"edges\"]\n",
    "\n",
    "EvolNode(meta_prompt = node_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EvalNode Test: \n",
    "At the beginning level, generation of EvalNode (when code is used here) should compile with success, and it should takes input and produce output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
