{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"left\">\n",
    "  <img src=\"img/abstract.png\" width=\"400\" alt=\"Funny little diagram\">\n",
    "  <p><em> Evolve nodes, evolve plans, and learn from the best performing ones.</em></p>\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating fitness: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Replacing with new node\n",
      " - Attempt 1 failed. Fitness: 0.75. Error:  Function runs with success rate: 75.0%, runs correctly with rate: 75.0%\n",
      "--- Compiled 3 out of 4 test cases\n",
      "--- Passed 3 out of 4 test cases\n",
      "Input: {'name': 'ChengXiao'}, Output is missing or of wrong type, Expected: {'age': 26}\n",
      "\n",
      "Error Message:\n",
      "--- Calling Prompt Function Error:\n",
      "Failed to parse LLM response: JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Parse Response Failed...\n",
      " - Attempt 2 failed. Fitness: 0.00. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Attempt 3 failed. Fitness: 0.50. Error:  Function runs with success rate: 50.0%, runs correctly with rate: 50.0%\n",
      "--- Compiled 2 out of 4 test cases\n",
      "--- Passed 2 out of 4 test cases\n",
      "Input: {'name': 'Dilireba'}, Output is missing or of wrong type, Expected: {'age': 32}\n",
      "Input: {'name': 'ChengXiao'}, Output is missing or of wrong type, Expected: {'age': 26}\n",
      "\n",
      "Error Message:\n",
      "--- Calling Prompt Function Error:\n",
      "Failed to parse LLM response: JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)--- Calling Prompt Function Error:\n",
      "Failed to parse LLM response: No JSON structure found in the provided text.\n",
      "Evolution failed after 3 attempts.\n",
      "Inspection on the generated code: \n",
      " def generate_prompt(name):\n",
      "    \"\"\"\n",
      "    Generate a prompt to guide an AI in getting the age of a celebrity.\n",
      "\n",
      "    Args:\n",
      "        name (str): The name of the celebrity.\n",
      "\n",
      "    Returns:\n",
      "        str: A string containing the final prompt for the AI.\n",
      "    \"\"\"\n",
      "    prompt = f'Get the age of {name}. Consider the following information: '\n",
      "    prompt += f\"Search Google for '{name} age' or similar phrases. \"\n",
      "    prompt += f'Take the potential age from the top search result(s). '\n",
      "    prompt += (\n",
      "        f\"Return a JSON-style response with a dictionary containing the age: {{'age': {name}'s age}}. \"\n",
      "        )\n",
      "    prompt += (\n",
      "        f'Consider updating this result with a search on Wikipedia if found, and format it as a JSON-style response.'\n",
      "        )\n",
      "    return prompt\n",
      "\n",
      "Output from the code: \n",
      " {'age': 31}\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.evolnode import EvolNode\n",
    "from methods.llm import get_groq_response, get_claude_response\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Search for age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.CODE)\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "\n",
    "test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "test_inputs = [c[0] for c in test_cases]\n",
    "\n",
    "node = EvolNode(mp, None, None, get_response=get_groq_response, test_cases=test_cases) # setting manual test cases\n",
    "# node = EvolNode(mp, None, None, get_response=get_groq_response) # automatic generation of test cases \n",
    "\n",
    "\n",
    "node.evolve(\"i1\", replace=True, max_attempts=3, num_runs=2) # Roll the dice 5 times, record the best one\n",
    "\n",
    "print(\"Inspection on the generated code: \\n\", node.code)\n",
    "\n",
    "import time \n",
    "time.sleep(3)\n",
    "\n",
    "input_dict = test_inputs[0]\n",
    "output_dict = node(input_dict) # Could still have error due to unsuccessful parsing of output\n",
    "print(\"Output from the code: \\n\", output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "# Population building phase ... \n",
    "from methods.llm import get_groq_response\n",
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.population import Evolution\n",
    "\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "\n",
    "test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "evo = Evolution(pop_size=3, meta_prompt=mp, get_response=get_groq_response, test_cases=test_cases, max_attempts=3, num_eval_runs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_population = [{'reasoning': \"To generate a prompt for an AI to find the age of a celebrity, I will incorporate a natural language approach, leveraging the search engine's ability to provide relevant information, while also specifying the required output format in the prompt for clarity.\",\n",
    "  'code': 'def generate_prompt(name):\\n    \"\"\"\\n    Generate a prompt to guide an AI in finding the age of a celebrity.\\n\\n    Parameters:\\n    name (str): The name of the celebrity.\\n\\n    Returns:\\n    str: A string containing the final prompt for the AI.\\n    \"\"\"\\n    prompt = (\\n        f\"Given the input \\'{name}\\', please provide a JSON-style response with the following structure: \"\\n        )\\n    prompt += (\\n        \"{\\'age\\': int(<age>)}}, where <age> is the age of the celebrity in years.\"\\n        )\\n    prompt += (\\n        \\' The response should be based on the latest available information from top search results.\\'\\n        )\\n    return prompt\\n',\n",
    "  'fitness': 1.0},\n",
    " {'reasoning': 'To calculate the age of a celebrity, we need to first search for their birth date or age online and then perform date arithmetic to find their current age. We can utilize this reasoning by using the search engine to find the relevant information and then utilizing AI to process the information and calculate the age.',\n",
    "  'code': 'def generate_prompt(name: str) ->str:\\n    \"\"\"\\n    Generates a prompt to guide an AI in calculating the age of a celebrity.\\n    \\n    Args:\\n    name (str): The name of the celebrity.\\n    \\n    Returns:\\n    str: A string containing the final prompt for the AI.\\n    \"\"\"\\n    prompt = (\"Given the name \\'\" + name +\\n        \"\\', use the search engine to find the birth date of \" + name +\\n        \\' and calculate their current age.\\')\\n    return (\\'Search google for result \\' + prompt +\\n        \", format the output as a JSON-style dictionary: {\\'age\\': int(...)}\")\\n',\n",
    "  'fitness': 1.0}] # to replace with loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MetaPrompt._get_prompt_m1() missing 1 required positional argument: 'indiv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# node_population = [] # build up some population first (so we need a chain of evolution methods 'strategy')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m node_population \u001b[38;5;241m=\u001b[39m \u001b[43mevo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_offspring\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_population\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/population.py:72\u001b[0m, in \u001b[0;36mEvolution._get_offspring\u001b[0;34m(self, operator, pop)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m# mutation operator\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     parents \u001b[38;5;241m=\u001b[39m parent_selection(pop, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# one parent used for mutation\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_attempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_eval_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m], offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m], offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mreasoning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mfitness\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# add offspring to population\u001b[39;00m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/evolnode.py:303\u001b[0m, in \u001b[0;36mEvolNode.evolve\u001b[0;34m(self, method, parents, replace, feedback, max_attempts, fitness_threshold, num_runs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Evolve many times\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_attempts):\n\u001b[0;32m--> 303\u001b[0m     reasoning, code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtmp_code \u001b[38;5;241m=\u001b[39m code   \n\u001b[1;32m    305\u001b[0m     fitness, error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_fitness(code\u001b[38;5;241m=\u001b[39mcode, max_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_runs\u001b[38;5;241m=\u001b[39mnum_runs)            \n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/evolnode.py:279\u001b[0m, in \u001b[0;36mEvolNode._evolve\u001b[0;34m(self, method, parents, replace, feedback)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, parents: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, feedback: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Note: Evolution process will be decoupled with the fitness assignment process\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_evolve_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m         reasoning, code \u001b[38;5;241m=\u001b[39m parse_evol_response(response)\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/evolnode.py:268\u001b[0m, in \u001b[0;36mEvolNode._get_evolve_response\u001b[0;34m(self, method, feedback)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_evolve_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, feedback: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    267\u001b[0m     prompt_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_prompt, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_get_prompt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 268\u001b[0m     prompt_content \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     prompt_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelevant_node_desc\n\u001b[1;32m    270\u001b[0m     prompt_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIdea: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m feedback \u001b[38;5;66;03m# External Guidance (perhaps we should reddit / stackoverflow this thingy)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: MetaPrompt._get_prompt_m1() missing 1 required positional argument: 'indiv'"
     ]
    }
   ],
   "source": [
    "# node_population = [] # build up some population first (so we need a chain of evolution methods 'strategy')\n",
    "node_population = evo._get_offspring(\"m1\", node_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reasoning': \"To generate a prompt for an AI to find the age of a celebrity, I will incorporate a natural language approach, leveraging the search engine's ability to provide relevant information, while also specifying the required output format in the prompt for clarity.\",\n",
       "  'code': 'def generate_prompt(name):\\n    \"\"\"\\n    Generate a prompt to guide an AI in finding the age of a celebrity.\\n\\n    Parameters:\\n    name (str): The name of the celebrity.\\n\\n    Returns:\\n    str: A string containing the final prompt for the AI.\\n    \"\"\"\\n    prompt = (\\n        f\"Given the input \\'{name}\\', please provide a JSON-style response with the following structure: \"\\n        )\\n    prompt += (\\n        \"{\\'age\\': int(<age>)}}, where <age> is the age of the celebrity in years.\"\\n        )\\n    prompt += (\\n        \\' The response should be based on the latest available information from top search results.\\'\\n        )\\n    return prompt\\n',\n",
       "  'fitness': 1.0},\n",
       " {'reasoning': 'To calculate the age of a celebrity, we need to first search for their birth date or age online and then perform date arithmetic to find their current age. We can utilize this reasoning by using the search engine to find the relevant information and then utilizing AI to process the information and calculate the age.',\n",
       "  'code': 'def generate_prompt(name: str) ->str:\\n    \"\"\"\\n    Generates a prompt to guide an AI in calculating the age of a celebrity.\\n    \\n    Args:\\n    name (str): The name of the celebrity.\\n    \\n    Returns:\\n    str: A string containing the final prompt for the AI.\\n    \"\"\"\\n    prompt = (\"Given the name \\'\" + name +\\n        \"\\', use the search engine to find the birth date of \" + name +\\n        \\' and calculate their current age.\\')\\n    return (\\'Search google for result \\' + prompt +\\n        \", format the output as a JSON-style dictionary: {\\'age\\': int(...)}\")\\n',\n",
       "  'fitness': 1.0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Evolution' object has no attribute 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# len(node_population)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_offspring\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_population\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/population.py:60\u001b[0m, in \u001b[0;36mEvolution._get_offspring\u001b[0;34m(self, operator, pop)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03mGenerate one offspring using specific operator \u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m- Select parent\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m- Evolve (crossover or mutation)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m offspring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m---> 60\u001b[0m parents \u001b[38;5;241m=\u001b[39m parent_selection(pop, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m operator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m operator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mevolve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi1\u001b[39m\u001b[38;5;124m\"\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_attempts, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_eval_runs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Evolution' object has no attribute 'm'"
     ]
    }
   ],
   "source": [
    "# len(node_population)\n",
    "\n",
    "evo._get_offspring(\"m1\", node_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def generate_prompt(name):\n",
      "    \"\"\"\n",
      "    Generate a prompt to guide an AI in completing the task of finding the age of a celebrity.\n",
      "\n",
      "    Parameters:\n",
      "    name (str): The name of the celebrity.\n",
      "\n",
      "    Returns:\n",
      "    str: A string containing the final prompt for the AI.\n",
      "    \"\"\"\n",
      "    prompt = (\n",
      "        f\"Please search for {name} and their age/biography on the internet, and return a JSON-style response with an output dictionary of the format {{'age': int(age)}}\"\n",
      "        )\n",
      "    return prompt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# len(node_population)\n",
    "\n",
    "code = node_population[1]['code']\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 2/2 [00:01<00:00,  1.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " ' Function runs with success rate: 100.0%, runs correctly with rate: 100.0%\\n--- Compiled 2 out of 2 test cases\\n--- Passed 2 out of 2 test cases\\n\\nError Message:\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evo.evol._evaluate_fitness(test_cases=test_cases, code=code) # error in evaluation metric ? (need debugging, prediction is 31, but GT is 32, yet it's judged to be correct ??)\n",
    "# evo.evol.call_prompt_function(code = code, test_input = test_cases[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Dilireba'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously, I need a 'reflective and fix shit-up evolution strategy here, too ...'\n",
    "# sth like 'what is the problem with the code given referrable sub-functions 'xxxxxxx'?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'name': 'Dilireba'}, {'age': 32}), ({'name': 'ChengXiao'}, {'age': 26})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:01,  2.61case/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.population import Evolution\n",
    "\n",
    "evo = Evolution(pop_size=3, meta_prompt=mp, get_response=get_groq_response, test_cases=test_cases, max_attempts=3, num_eval_runs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Loading Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 32}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.evolnode import EvolNode \n",
    "from methods.llm import get_groq_response\n",
    "\n",
    "node = EvolNode.load(\"get_celeb_age\", get_response=get_groq_response)\n",
    "# node = EvolNode.load(\"search_google\")\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from datetime import datetime\n",
      "import http.client\n",
      "import json\n",
      "import os\n",
      "from typing import Dict, Any\n",
      "\n",
      "\n",
      "def _search_google(query: str) ->Dict[str, Any]:\n",
      "    \"\"\"\n",
      "    Use Serper API to search Google for information\n",
      "    \n",
      "    Args:\n",
      "        query (str): The search query\n",
      "    \n",
      "    Returns:\n",
      "        Dict[str, Any]: Parsed JSON response from the API\n",
      "    \"\"\"\n",
      "    conn = http.client.HTTPSConnection('google.serper.dev')\n",
      "    payload = json.dumps({'q': query})\n",
      "    headers = {'X-API-KEY': os.environ['SERPER_API_KEY'], 'Content-Type':\n",
      "        'application/json'}\n",
      "    try:\n",
      "        conn.request('POST', '/search', payload, headers)\n",
      "        res = conn.getresponse()\n",
      "        data = res.read()\n",
      "        return json.loads(data.decode('utf-8'))\n",
      "    except Exception as e:\n",
      "        print(f'Error occurred during API request: {str(e)}')\n",
      "        return {}\n",
      "    finally:\n",
      "        conn.close()\n",
      "\n",
      "\n",
      "def search_google(query: str) ->str:\n",
      "    \"\"\" \n",
      "    Input query, return search result string from Google\n",
      "    \"\"\"\n",
      "    result = _search_google(query)\n",
      "    result_dict = {k.replace('organic', 'Search Result'): v for k, v in\n",
      "        result.items() if k in ['answerBox', 'organic']}\n",
      "    result_str = json.dumps(result_dict, indent=2)\n",
      "    return result_str\n",
      "\n",
      "\n",
      "def generate_prompt(name):\n",
      "    current_year = datetime.now().year\n",
      "    search_query = f'{name} birth date'\n",
      "    search_result = search_google(search_query)\n",
      "    prompt = f\"\"\"\n",
      "    Based on the following information about {name}, please determine their current age:\n",
      "\n",
      "    Search results: {search_result}\n",
      "\n",
      "    Calculate the age by subtracting the birth year from the current year ({current_year}).\n",
      "\n",
      "    Please provide the result in the following JSON format:\n",
      "    {{\n",
      "        \"age\": int(calculated_age)\n",
      "    }}\n",
      "\n",
      "    If the birth date is not found or unclear, return null for the age value.\n",
      "    \"\"\"\n",
      "    return prompt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(node.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alignment-Check for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.llm import get_groq_response \n",
    "\n",
    "# Evaluation base on alignment check\n",
    "node.get_response = get_groq_response \n",
    "fitness, issue_summary = node._evaluate_fitness(max_tries=1, num_runs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"1000\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/Planning-node.png\" width=\"400\" alt=\"Planning Node Task Decomposition\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "success: successfully compiled d2_output/plan_graph.d2 to d2_output/plan_graph.png in 207.111084ms\n",
      "success: successfully compiled d2_output/plan_graph_dag.d2 to d2_output/plan_graph_dag.png in 207.980416ms\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_claude_response\n",
    "from methods.diagram import visualize_plan_dict\n",
    "from methods.meta_prompt import MetaPlan,extract_python_code, extract_json_from_text\n",
    "\n",
    "# Step 0. Initialize MetaPlanning Prompt\n",
    "mp = MetaPlan(\"Get the age of celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"])\n",
    "\n",
    "# Step 1: Generate Pseudo-Code for SubTask Decomposition\n",
    "prompt = mp._get_pseudo_code_prompt() # Pseudo-Code Prompt (Non-implemented functional)\n",
    "response = get_claude_response(prompt) # Use Strong LLM to build up pseudo-code\n",
    "code = extract_python_code(response) # Extract Python Code from response \n",
    "\n",
    "# Step 2: Generate Planning DAG: Multiple Nodes \n",
    "graph_prompt = mp._get_plan_graph_prompt(code) \n",
    "plan_response = get_claude_response(graph_prompt)\n",
    "plan_dict = extract_json_from_text(plan_response)\n",
    "\n",
    "visualize_plan_dict(plan_dict)\n",
    "\n",
    "# Step 3: Spawn Multiple Sub-Nodes and Evolve them\n",
    "\n",
    "# Step 4: Slot Sub Node into context for parent node re-write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "# Ok we could load this thing now ..\n",
    "\n",
    "from methods.eoh_evolution import PlanNode \n",
    "from methods.llm import get_groq_response \n",
    "\n",
    "plan_node = PlanNode.load(\"get_celeb_age\", get_response=get_groq_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_dict = plan_node.plan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:05,  1.20s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:09,  1.99s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:06,  1.20s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:05,  1.07s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:04,  1.17case/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:05,  1.19s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:05,  1.13s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 100%|██████████| 3/3 [00:04<00:00,  1.61s/case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 3 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:06,  1.28s/case]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases: 5case [00:10,  2.19s/case]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated 5 test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_nodes, code_nodes = plan_node._spawn_nodes(plan_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'name': 'Tom Hanks'}, {'data': '67'}),\n",
       " ({'name': 'Emma Watson'}, {'data': '33'}),\n",
       " ({'name': 'Leonardo da Vinci'}, {'data': 'Deceased'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chicken n Egg problem: - how can you evolve a function which you can't evaluate? \n",
    "code_nodes[\"scrape_celeb_data\"].test_cases # probably not fair to expect test-cases for this one to be grounded ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Attempt 1 failed. Fitness: 0.00. Error: --- Compiled 10 out of 15 test cases\n",
      "--- Passed 0 out of 15 test cases\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Input: {'name': 'Emma Watson'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': '33'}\n",
      "Input: {'name': 'Leonardo da Vinci'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': 'Deceased'}\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Input: {'name': 'Emma Watson'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': '33'}\n",
      "Input: {'name': 'Leonardo da Vinci'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': 'Deceased'}\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Input: {'name': 'Emma Watson'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': '33'}\n",
      "Input: {'name': 'Leonardo da Vinci'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': 'Deceased'}\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Input: {'name': 'Emma Watson'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': '33'}\n",
      "Input: {'name': 'Leonardo da Vinci'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': 'Deceased'}\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Input: {'name': 'Emma Watson'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': '33'}\n",
      "Input: {'name': 'Leonardo da Vinci'}, Pred: {'data': 'Celebrity not found.'}, Expected: {'data': 'Deceased'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 15/15 [00:00<00:00, 44906.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Attempt 2 failed. Fitness: 0.00. Error: --- Compiled 0 out of 15 test cases\n",
      "--- Passed 0 out of 15 test cases\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 15/15 [00:00<00:00, 31583.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Attempt 3 failed. Fitness: 0.00. Error: --- Compiled 0 out of 15 test cases\n",
      "--- Passed 0 out of 15 test cases\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness: 100%|██████████| 15/15 [00:00<00:00, 7772.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Attempt 4 failed. Fitness: 0.00. Error: --- Compiled 0 out of 15 test cases\n",
      "--- Passed 0 out of 15 test cases\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Tom Hanks'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Emma Watson'}. Can't parse output dictionary from LLM's response.\n",
      "Given Input: {'name': 'Leonardo da Vinci'}. Can't parse output dictionary from LLM's response.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating fitness:   0%|          | 0/15 [01:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m scrape_node \u001b[38;5;241m=\u001b[39m code_nodes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrape_celeb_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mscrape_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:167\u001b[0m, in \u001b[0;36mEvolNode.evolve\u001b[0;34m(self, method, parents, replace, max_attempts, fitness_threshold, num_runs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_attempts):\n\u001b[1;32m    166\u001b[0m     reasoning, code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evolve(method, parents, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)    \n\u001b[0;32m--> 167\u001b[0m     _, fitness, error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_runs\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fitness \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:259\u001b[0m, in \u001b[0;36mEvolNode._evaluate_fitness\u001b[0;34m(self, test_cases, code, max_tries, num_runs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_prompt\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m PromptMode\u001b[38;5;241m.\u001b[39mCODE:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m         output_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_code_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m         compiled_tests \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m         is_aligned \u001b[38;5;241m=\u001b[39m check_alignment(output_dict, test_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response)\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:228\u001b[0m, in \u001b[0;36mEvolNode.call_code_func\u001b[0;34m(self, test_input, code, file_path)\u001b[0m\n\u001b[1;32m    226\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 228\u001b[0m     output_value \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     output_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_prompt\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    230\u001b[0m     output_dict \u001b[38;5;241m=\u001b[39m {output_name: output_value}\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/meta_execute.py:88\u001b[0m, in \u001b[0;36mcall_func_code\u001b[0;34m(input_data, code, func_name, file_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data type mismatch for parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(actual_value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Call the function with the input data\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Check output type\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_return_type \u001b[38;5;241m!=\u001b[39m Any \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_type(result, expected_return_type):\n",
      "File \u001b[0;32m<string>:20\u001b[0m, in \u001b[0;36mscrape_celeb_data\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    617\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrape_node = code_nodes[\"scrape_celeb_data\"]\n",
    "\n",
    "scrape_node.evolve(\"i1\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Node evolution is bad now, parsing seems to be problematic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined structured data to locate the celebrity based on their name and then retrieving their corresponding age.}\n",
      "\n",
      "```python\n",
      "def scrape_celeb_data(name: str) -> str:\n",
      "    # Predefined mock data to simulate web data\n",
      "    celeb_data = {\n",
      "        \"Taylor Swift\": 33,\n",
      "        \"Leonardo DiCaprio\": 48,\n",
      "        \"Beyoncé\": 42,\n",
      "        \"Chris Evans\": 42,\n",
      "        \"Scarlett Johansson\": 38\n",
      "    }\n",
      "    \n",
      "    # Attempt to find the celebrity's age\n",
      "    age = celeb_data.get(name)\n",
      "\n",
      "    # If age not found, return a message\n",
      "    if age is None:\n",
      "        return f\"Age for {name} not found.\"\n",
      "    \n",
      "    # Return the age as a string\n",
      "    return f\"{name} is {age} years old.\"\n"
     ]
    }
   ],
   "source": [
    "code = scrape_node.code\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolve Sub-Nodes (hope is not too slow here ...)\n",
    "# 1. Code success -> end | else -> Prompt | pick best -> return node for specific sub-task\n",
    "\n",
    "# prompt_nodes, code_nodes = plan_node._spawn_nodes(plan_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'Search for celebrity in database',\n",
       "  'name': 'search_celebrity_database',\n",
       "  'inputs': ['name'],\n",
       "  'input_types': ['str'],\n",
       "  'outputs': ['celeb_info'],\n",
       "  'output_types': ['dict'],\n",
       "  'target': 'Retrieve celebrity information',\n",
       "  'mode': 'CODE'},\n",
       " {'task': 'Extract birth date from celebrity info',\n",
       "  'name': 'extract_birth_date',\n",
       "  'inputs': ['celeb_info'],\n",
       "  'input_types': ['dict'],\n",
       "  'outputs': ['birth_date'],\n",
       "  'output_types': ['date'],\n",
       "  'target': \"Get celebrity's birth date\",\n",
       "  'mode': 'CODE'},\n",
       " {'task': 'Get current date',\n",
       "  'name': 'get_current_date',\n",
       "  'inputs': [],\n",
       "  'input_types': [],\n",
       "  'outputs': ['current_date'],\n",
       "  'output_types': ['date'],\n",
       "  'target': 'Obtain current date for age calculation',\n",
       "  'mode': 'CODE'},\n",
       " {'task': 'Calculate age based on birth date and current date',\n",
       "  'name': 'calculate_age',\n",
       "  'inputs': ['birth_date', 'current_date'],\n",
       "  'input_types': ['date', 'date'],\n",
       "  'outputs': ['age'],\n",
       "  'output_types': ['int'],\n",
       "  'target': \"Determine celebrity's current age\",\n",
       "  'mode': 'CODE'},\n",
       " {'task': 'Get celebrity age',\n",
       "  'name': 'get_celeb_age',\n",
       "  'inputs': ['name'],\n",
       "  'input_types': ['str'],\n",
       "  'outputs': ['age'],\n",
       "  'output_types': ['int'],\n",
       "  'target': \"Retrieve and return celebrity's age\",\n",
       "  'mode': 'CODE'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize_plan_dict(plan_dict)\n",
    "\n",
    "plan_dict # Ignore the mode for now, let's use both mode and pick the best performing ones ... \n",
    "\n",
    "plan_dict[\"nodes\"]\n",
    "\n",
    "# Basic Idea: \n",
    "# - Build node libraries is the better way to describe this \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
