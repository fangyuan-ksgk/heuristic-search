{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/evolnode.png\" width=\"800\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Evolution Node free you from coding and debugging, let LLM evolve your code for you.</em></p>\n",
    "</div>\n",
    "<div align=\"left\">\n",
    "<p><em>Bored of manual coding, a function? EvolNode let LLM automate function design and guide the evolution of it with genetic algorithm. A node here takes a task, input, and output, it uses either code or another LLM to complete the task, ensuring aligned input and output value types and ,.names.Fitness evaluation is done by running the function with a few specified test cases, the more diverse the test case, the better the evolution.\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# input_dict = {\"n\": 10}\n",
    "# reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # Evolution with guaranteed structural fitness\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "node = EvolNode(mp, None, None)\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "reasoning, code = node.evolve([input_dict], \"i1\", replace=True)\n",
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"1000\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaPrompt I1: \n",
      "Goal: Help me date Dilireba, I'm a white colar worker living on salary.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON-style plan represented as a Directed Acyclic Graph (DAG) to achieve the goal. Use creative topology in the DAG, include parallel tasks if required.\n",
      "\n",
      "The plan should include:\n",
      "\n",
      "- **Nodes**: Each node represents a key action or step and must contain the following attributes:\n",
      "  - `task`: Description of the task.\n",
      "  - `name`: Concise name used for the task function.\n",
      "  - `input`: The resources, information, or prerequisites needed to perform the action.\n",
      "  - `output`: The immediate result or outcome of the action.\n",
      "  - `target`: The purpose or goal that the action contributes to.\n",
      "  - `mode`: The execution mode for this task (\"CODE\" or \"PROMPT\").\n",
      "\n",
      "- **Edges**: Each edge represents a dependency or relationship between nodes, indicating that one step supports or leads to another.\n",
      "  - `source`: The `id` of the source node (the preceding action).\n",
      "  - `target`: The `id` of the target node (the subsequent action).\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"task\": \"Task 1\",\n",
      "      \"name\": \"task_1\"\n",
      "      \"input\": \"Inputs required for Action 1\",\n",
      "      \"output\": \"Outputs/result of Action 1\",\n",
      "      \"target\": \"Purpose of Action 1\"\n",
      "      \"mode\": \"CODE\"\n",
      "    },\n",
      "    {\n",
      "      \"task\": \"Task 2\",\n",
      "      \"name\": \"task_2\",\n",
      "      \"input\": \"Inputs required for Action 2\",\n",
      "      \"output\": \"Outputs/result of Action 2\",\n",
      "      \"target\": \"Purpose of Action 2\",\n",
      "      \"mode\": \"PROMPT\"\n",
      "    }\n",
      "    // Add more nodes as needed\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\n",
      "      \"source\": \"task_1\",\n",
      "      \"target\": \"task_2\"\n",
      "    }\n",
      "    // Add more edges as needed\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "print(\"MetaPrompt I1: \")\n",
    "print(prompt)\n",
    "\n",
    "from methods.llm import get_openai_response\n",
    "response = get_openai_response(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# from methods.meta_prompt import parse_json_from_response\n",
    "\n",
    "tactic = re.findall(r\"\\{(.*)\\}\", response, re.DOTALL)\n",
    "plan_dict = extract_json_from_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<methods.eoh_evolution.EvolNode at 0x2893758d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, MetaPlan, extract_json_from_text\n",
    "from methods.eoh_evolution import EvolNode\n",
    "from methods.llm import get_openai_response as get_response\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Collect MetaPrompt from parsed Plan-Graph Response\n",
    "meta_node_prompts = []\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(task=node.get(\"task\"),  func_name=node.get(\"name\"), input=node.get(\"input\"), output=node.get(\"output\"), mode=node.get(\"mode\").lower())\n",
    "    meta_node_prompts.append(node_prompt)\n",
    "    \n",
    "edges = plan_dict[\"edges\"]\n",
    "\n",
    "EvolNode(meta_prompt = node_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EvalNode Test: \n",
    "At the beginning level, generation of EvalNode (when code is used here) should compile with success, and it should takes input and produce output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Python files:\n",
      "1. models.py\n",
      "2. reasoning_dataset.py\n",
      "3. dataset.py\n",
      "4. irem_baseline.py\n",
      "5. gen_planning_dataset.py\n",
      "6. planning_dataset.py\n",
      "7. train.py\n",
      "8. sat_dataset.py\n",
      "9. diffusion_lib/denoising_diffusion_pytorch_1d.py\n",
      "10. diffusion_lib/transformer.py\n",
      "11. diffusion_lib/nlm.py\n",
      "12. diffusion_lib/nlm_utils.py\n",
      "13. irem_lib/irem.py\n",
      "Building dependency graph for models.py...\n",
      "Visualizing graph...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/Z3JhcGggVEQKICAgIGZpbGVfMVsibW9kZWxzLnB5Il0KICAgIGZpbGVfMV9zd2lzaFsic3dpc2giXQogICAgZmlsZV8xX3N3aXNoIC0tPiBmaWxlXzEKICAgIGZpbGVfMV9fX2luaXRfX1siX19pbml0X18iXQogICAgZmlsZV8xX19faW5pdF9fIC0tPiBmaWxlXzEKICAgIGZpbGVfMV9fX2luaXRfXyAtLT4gZmlsZV8xX3N1cGVyCiAgICBmaWxlXzFfZm9yd2FyZFsiZm9yd2FyZCJdCiAgICBmaWxlXzFfZm9yd2FyZCAtLT4gZmlsZV8xCiAgICBmaWxlXzFfZGVjb2RlWyJkZWNvZGUiXQogICAgZmlsZV8xX2RlY29kZSAtLT4gZmlsZV8xCiAgICBmaWxlXzFfcmFuZG5bInJhbmRuIl0KICAgIGZpbGVfMV9yYW5kbiAtLT4gZmlsZV8xCiAgICBmaWxlXzEgLS0-IGZpbGVfMgogICAgZmlsZV8yWyJubG0ucHkiXQogICAgZmlsZV8yX19nZXRfdHVwbGVfblsiX2dldF90dXBsZV9uIl0KICAgIGZpbGVfMl9fZ2V0X3R1cGxlX24gLS0-IGZpbGVfMgogICAgZmlsZV8yX19nZXRfdHVwbGVfbiAtLT4gZmlsZV8yX2xlbgogICAgZmlsZV8yX19nZXRfdHVwbGVfbiAtLT4gZmlsZV8yX3R5cGUKICAgIGZpbGVfMl9fX2luaXRfX1siX19pbml0X18iXQogICAgZmlsZV8yX19faW5pdF9fIC0tPiBmaWxlXzIKICAgIGZpbGVfMl9fX2luaXRfXyAtLT4gZmlsZV8yX3N1cGVyCiAgICBmaWxlXzJfX19pbml0X18gLS0-IGZpbGVfMl9Mb2dpY0xheWVyCiAgICBmaWxlXzJfX19pbml0X18gLS0-IGZpbGVfMl9sZW4KICAgIGZpbGVfMl9fX2luaXRfXyAtLT4gZmlsZV8yX3JhbmdlCiAgICBmaWxlXzJfX19pbml0X18gLS0-IGZpbGVfMl9hZGRfCiAgICBmaWxlXzJfZm9yd2FyZFsiZm9yd2FyZCJdCiAgICBmaWxlXzJfZm9yd2FyZCAtLT4gZmlsZV8yCiAgICBmaWxlXzJfZm9yd2FyZCAtLT4gZmlsZV8yX3JhbmdlCiAgICBmaWxlXzJfZm9yd2FyZCAtLT4gZmlsZV8yX2VudW1lcmF0ZQogICAgZmlsZV8yX2ZvcndhcmQgLS0-IGZpbGVfMl9sYXllcgogICAgZmlsZV8yX2ZvcndhcmQgLS0-IGZpbGVfMl9tZXJnZQogICAgZmlsZV8yX2ZvcndhcmQgLS0-IGZpbGVfMl9taW4KICAgIGZpbGVfMl9tYWtlX3Byb2dfYmxvY2tfcGFyc2VyWyJtYWtlX3Byb2dfYmxvY2tfcGFyc2VyIl0KICAgIGZpbGVfMl9tYWtlX3Byb2dfYmxvY2tfcGFyc2VyIC0tPiBmaWxlXzIKICAgIGZpbGVfMl9tYWtlX3Byb2dfYmxvY2tfcGFyc2VyIC0tPiBmaWxlXzJfc3RyCiAgICBmaWxlXzJfZnJvbV9hcmdzWyJmcm9tX2FyZ3MiXQogICAgZmlsZV8yX2Zyb21fYXJncyAtLT4gZmlsZV8yCiAgICBmaWxlXzJfZnJvbV9hcmdzIC0tPiBmaWxlXzJfc3RyCiAgICBmaWxlXzJfZnJvbV9hcmdzIC0tPiBmaWxlXzJfY2xzCiAgICBmaWxlXzJfZnJvbV9hcmdzIC0tPiBmaWxlXzJfZ2V0YXR0cgogICAgZmlsZV8yX2Zyb21fYXJncyAtLT4gZmlsZV8yX3NldGF0dHIKICAgIGZpbGVfMl9fbWFza1siX21hc2siXQogICAgZmlsZV8yX19tYXNrIC0tPiBmaWxlXzIKICAgIGZpbGVfMl9fbWFzayAtLT4gZmlsZV8yX2xlbgogICAgZmlsZV8yX19tYXNrIC0tPiBmaWxlXzJfemlwCiAgICBmaWxlXzJfYWRkX1siYWRkXyJdCiAgICBmaWxlXzJfYWRkXyAtLT4gZmlsZV8yCiAgICBmaWxlXzJfYWRkXyAtLT4gZmlsZV8yX2xlbgogICAgZmlsZV8yX2FkZF8gLS0-IGZpbGVfMl9yYW5nZQogICAgZmlsZV8yX21lcmdlWyJtZXJnZSJdCiAgICBmaWxlXzJfbWVyZ2UgLS0-IGZpbGVfMgogICAgZmlsZV8yIC0tPiBmaWxlXzMKICAgIGZpbGVfM1sibmxtX3V0aWxzLnB5Il0KICAgIGZpbGVfM19icm9hZGNhc3RbImJyb2FkY2FzdCJdCiAgICBmaWxlXzNfYnJvYWRjYXN0IC0tPiBmaWxlXzMKICAgIGZpbGVfM19icm9hZGNhc3QgLS0-IGZpbGVfM19jb25jYXRfc2hhcGUKICAgIGZpbGVfM19jb25jYXRfc2hhcGVbImNvbmNhdF9zaGFwZSJdCiAgICBmaWxlXzNfY29uY2F0X3NoYXBlIC0tPiBmaWxlXzMKICAgIGZpbGVfM19jb25jYXRfc2hhcGUgLS0-IGZpbGVfM19pbnQKICAgIGZpbGVfM19jb25jYXRfc2hhcGUgLS0-IGZpbGVfM190dXBsZQogICAgZmlsZV8zX2NvbmNhdF9zaGFwZSAtLT4gZmlsZV8zX2lzaW5zdGFuY2UKICAgIGZpbGVfM19tZXNoZ3JpZFsibWVzaGdyaWQiXQogICAgZmlsZV8zX21lc2hncmlkIC0tPiBmaWxlXzMKICAgIGZpbGVfM19tZXNoZ3JpZCAtLT4gZmlsZV8zX2Jyb2FkY2FzdAogICAgZmlsZV8zX21lc2hncmlkX2V4Y2x1ZGVfc2VsZlsibWVzaGdyaWRfZXhjbHVkZV9zZWxmIl0KICAgIGZpbGVfM19tZXNoZ3JpZF9leGNsdWRlX3NlbGYgLS0-IGZpbGVfMwogICAgZmlsZV8zX21lc2hncmlkX2V4Y2x1ZGVfc2VsZiAtLT4gZmlsZV8zX2NvbmNhdF9zaGFwZQogICAgZmlsZV8zX21lc2hncmlkX2V4Y2x1ZGVfc2VsZiAtLT4gZmlsZV8zX3JhbmdlCiAgICBmaWxlXzNfZXhjbHVkZV9tYXNrWyJleGNsdWRlX21hc2siXQogICAgZmlsZV8zX2V4Y2x1ZGVfbWFzayAtLT4gZmlsZV8zCiAgICBmaWxlXzNfZXhjbHVkZV9tYXNrIC0tPiBmaWxlXzNfcmFuZ2UKICAgIGZpbGVfM19tYXNrX3ZhbHVlWyJtYXNrX3ZhbHVlIl0KICAgIGZpbGVfM19tYXNrX3ZhbHVlIC0tPiBmaWxlXzMKICAgIGZpbGVfM19nZXRfYmF0Y25ub3JtWyJnZXRfYmF0Y25ub3JtIl0KICAgIGZpbGVfM19nZXRfYmF0Y25ub3JtIC0tPiBmaWxlXzMKICAgIGZpbGVfM19nZXRfYmF0Y25ub3JtIC0tPiBmaWxlXzNfTm90SW1wbGVtZW50ZWRFcnJvcgogICAgZmlsZV8zX2dldF9iYXRjbm5vcm0gLS0-IGZpbGVfM19WYWx1ZUVycm9yCiAgICBmaWxlXzNfZ2V0X2JhdGNubm9ybSAtLT4gZmlsZV8zX2dldGF0dHIKICAgIGZpbGVfM19nZXRfYmF0Y25ub3JtIC0tPiBmaWxlXzNfaXNpbnN0YW5jZQogICAgZmlsZV8zX2dldF9kcm9wb3V0WyJnZXRfZHJvcG91dCJdCiAgICBmaWxlXzNfZ2V0X2Ryb3BvdXQgLS0-IGZpbGVfMwogICAgZmlsZV8zX2dldF9kcm9wb3V0IC0tPiBmaWxlXzNfZ2V0YXR0cgogICAgZmlsZV8zX2dldF9kcm9wb3V0IC0tPiBmaWxlXzNfaXNpbnN0YW5jZQogICAgZmlsZV8zX2dldF9hY3RpdmF0aW9uWyJnZXRfYWN0aXZhdGlvbiJdCiAgICBmaWxlXzNfZ2V0X2FjdGl2YXRpb24gLS0-IGZpbGVfMwogICAgZmlsZV8zX2dldF9hY3RpdmF0aW9uIC0tPiBmaWxlXzNfVmFsdWVFcnJvcgogICAgZmlsZV8zX2dldF9hY3RpdmF0aW9uIC0tPiBmaWxlXzNfZ2V0YXR0cgogICAgZmlsZV8zX2dldF9hY3RpdmF0aW9uIC0tPiBmaWxlXzNfdHlwZQogICAgZmlsZV8zX2dldF9hY3RpdmF0aW9uIC0tPiBmaWxlXzNfaXNpbnN0YW5jZQogICAgZmlsZV8zX2dldF9vdXRwdXRfZGltWyJnZXRfb3V0cHV0X2RpbSJdCiAgICBmaWxlXzNfZ2V0X291dHB1dF9kaW0gLS0-IGZpbGVfMwogICAgZmlsZV8zX2dldF9vdXRwdXRfZGltIC0tPiBmaWxlXzNfVmFsdWVFcnJvcgogICAgZmlsZV8zX19faW5pdF9fWyJfX2luaXRfXyJdCiAgICBmaWxlXzNfX19pbml0X18gLS0-IGZpbGVfMwogICAgZmlsZV8zX19faW5pdF9fIC0tPiBmaWxlXzNfc3VwZXIKICAgIGZpbGVfM19mb3J3YXJkWyJmb3J3YXJkIl0KICAgIGZpbGVfM19mb3J3YXJkIC0tPiBmaWxlXzMKICAgIGZpbGVfM19mb3J3YXJkIC0tPiBmaWxlXzNfbWVzaGdyaWRfZXhjbHVkZV9zZWxmCiAgICBmaWxlXzNfZm9yd2FyZCAtLT4gZmlsZV8zX1ZhbHVlRXJyb3IKICAgIGZpbGVfM19mb3J3YXJkIC0tPiBmaWxlXzNfbWVzaGdyaWQKICAgIGZpbGVfM19pbnB1dF9kaW1bImlucHV0X2RpbSJdCiAgICBmaWxlXzNfaW5wdXRfZGltIC0tPiBmaWxlXzMKICAgIGZpbGVfM19vdXRwdXRfZGltWyJvdXRwdXRfZGltIl0KICAgIGZpbGVfM19vdXRwdXRfZGltIC0tPiBmaWxlXzMKICAgIGZpbGVfM19yZXNldF9wYXJhbWV0ZXJzWyJyZXNldF9wYXJhbWV0ZXJzIl0KICAgIGZpbGVfM19yZXNldF9wYXJhbWV0ZXJzIC0tPiBmaWxlXzMKICAgIGZpbGVfM19yZXNldF9wYXJhbWV0ZXJzIC0tPiBmaWxlXzNfaXNpbnN0YW5jZQogICAgZmlsZV8zX19fcmVwcl9fWyJfX3JlcHJfXyJdCiAgICBmaWxlXzNfX19yZXByX18gLS0-IGZpbGVfMwogICAgZmlsZV8xIC0tPiBmaWxlXzQKICAgIGZpbGVfNFsidHJhbnNmb3JtZXIucHkiXQogICAgZmlsZV80X19faW5pdF9fWyJfX2luaXRfXyJdCiAgICBmaWxlXzRfX19pbml0X18gLS0-IGZpbGVfNAogICAgZmlsZV80X19faW5pdF9fIC0tPiBmaWxlXzRfc3VwZXIKICAgIGZpbGVfNF9fX2luaXRfXyAtLT4gZmlsZV80X0Jsb2NrCiAgICBmaWxlXzRfX19pbml0X18gLS0-IGZpbGVfNF9zdW0KICAgIGZpbGVfNF9fX2luaXRfXyAtLT4gZmlsZV80X3JhbmdlCiAgICBmaWxlXzRfX19pbml0X18gLS0-IGZpbGVfNF9wcmludAogICAgZmlsZV80X2ZvcndhcmRbImZvcndhcmQiXQogICAgZmlsZV80X2ZvcndhcmQgLS0-IGZpbGVfNAogICAgZmlsZV80X2ZvcndhcmQgLS0-IGZpbGVfNF9ibG9jawogICAgZmlsZV80X19pbml0X3dlaWdodHNbIl9pbml0X3dlaWdodHMiXQogICAgZmlsZV80X19pbml0X3dlaWdodHMgLS0-IGZpbGVfNAogICAgZmlsZV80X19pbml0X3dlaWdodHMgLS0-IGZpbGVfNF9pc2luc3RhbmNlCiAgICBmaWxlXzRfbWFrZV9vcHRpbWl6ZXJbIm1ha2Vfb3B0aW1pemVyIl0KICAgIGZpbGVfNF9tYWtlX29wdGltaXplciAtLT4gZmlsZV80CiAgICBmaWxlXzRfbWFrZV9vcHRpbWl6ZXIgLS0-IGZpbGVfNF9zb3J0ZWQKICAgIGZpbGVfNF9tYWtlX29wdGltaXplciAtLT4gZmlsZV80X2lzaW5zdGFuY2UKICAgIGZpbGVfNF9tYWtlX29wdGltaXplciAtLT4gZmlsZV80X3NldAogICAgZmlsZV80X21ha2Vfb3B0aW1pemVyIC0tPiBmaWxlXzRfc3RyCiAgICBmaWxlXzRfbWFrZV9vcHRpbWl6ZXIgLS0-IGZpbGVfNF9saXN0CiAgICBmaWxlXzRfbWFrZV9vcHRpbWl6ZXIgLS0-IGZpbGVfNF9sZW4=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function-level dependency graph saved as 'function_level_dependency_graph.png'\n",
      "Function-level Mermaid graph saved to 'function_level_dependency_graph.mmd'\n"
     ]
    }
   ],
   "source": [
    "from tools.repo import *\n",
    "\n",
    "\n",
    "def main():\n",
    "    repo_url = input(\"Enter the github repo your are interested: \")\n",
    "    repo_url = \"https://github.com/yilundu/ired_code_release\"\n",
    "    temp_repo = \"temp_dir\"\n",
    "    clone_repo(repo_url, temp_repo)\n",
    "    python_files = get_python_files(temp_repo)\n",
    "    \n",
    "    print(\"Available Python files:\")\n",
    "    for i, file in enumerate(python_files):\n",
    "        print(f\"{i+1}. {file}\")\n",
    "    \n",
    "    choice = int(input(\"Enter the number of the file you want to analyze: \")) - 1\n",
    "    start_file = python_files[choice]\n",
    "    \n",
    "    print(f\"Building dependency graph for {start_file}...\")\n",
    "    graph = build_function_level_mermaid_graph(start_file, temp_repo)\n",
    "    # graph = build_mermaid_graph(start_file, temp_repo)\n",
    "    \n",
    "    print(\"Visualizing graph...\")\n",
    "    visualize_function_level_graph(graph)\n",
    "\n",
    "    import shutil\n",
    "    shutil.rmtree(temp_repo)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Visualization SVG: \n",
    "\n",
    "https://www.mermaidchart.com/raw/1293d948-14f5-48d4-b05b-faa229167537?theme=light&version=v0.1&format=svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already cloned, skipping cloning...\n",
      "Function-level Mermaid graph saved to 'function_level_dependency_graph.mmd'\n"
     ]
    }
   ],
   "source": [
    "from tools.repo import *\n",
    "\n",
    "# Seems to have bug therein ... \n",
    "# repo_url = input(\"Enter the github repo your are interested: \")\n",
    "repo_url = \"https://github.com/yilundu/ired_code_release\"\n",
    "\n",
    "\n",
    "\n",
    "temp_repo = \"temp_repo\"\n",
    "if not os.path.exists(temp_repo):\n",
    "    clone_repo(repo_url, temp_repo)\n",
    "else:\n",
    "    print(\"Repo already cloned, skipping cloning...\")\n",
    "\n",
    "python_files = get_python_files(temp_repo) # get all python files \n",
    "start_file = python_files[0] # pick the first one for debugging purpose \n",
    "\n",
    "graph = build_cross_file_mermaid_graph(temp_repo, start_file)\n",
    "\n",
    "# target_object = \"Attention\"\n",
    "target_object = \"diffusion_lib/transformer.py\"\n",
    "# target_object = \"EBM\"\n",
    "target_object = \"models.py\"\n",
    "\n",
    "sub_graph = extract_subgraph(graph, target_object, max_depth=2)\n",
    "\n",
    "# write result sub_graph to .mmd file\n",
    "# Write the subgraph to a .mmd file\n",
    "with open(\"function_level_dependency_graph.mmd\", \"w\") as f:\n",
    "    f.write(sub_graph)\n",
    "print(\"Function-level Mermaid graph saved to 'function_level_dependency_graph.mmd'\")\n",
    "\n",
    "\n",
    "# Visualize the subgraph\n",
    "# visualize_function_level_graph(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph TD\n",
      "    node35[\"__init__\"]\n",
      "    node35 --> node15\n",
      "    node4[\"__init__\"]\n",
      "    node5[\"forward\"]\n",
      "    node13[\"__init__\"]\n",
      "    node11[\"forward\"]\n",
      "    node78[\"diffusion_lib/transformer.py\"]\n",
      "    node78 --> node82\n",
      "    node78 --> node85\n",
      "    node78 --> node79\n",
      "    node19[\"__init__\"]\n",
      "    node19 --> node15\n",
      "    node103[\"diffusion_lib/nlm_utils.py\"]\n",
      "    node16[\"__init__\"]\n",
      "    node39[\"forward\"]\n",
      "    node33[\"forward\"]\n",
      "    node33 --> node2\n",
      "    node41[\"__init__\"]\n",
      "    node41 --> node15\n",
      "    node90[\"diffusion_lib/nlm.py\"]\n",
      "    node90 --> node91\n",
      "    node90 --> node97\n",
      "    node90 --> node92\n",
      "    node90 -..-> node103\n",
      "    node7[\"__init__\"]\n",
      "    node18[\"EBM\"]\n",
      "    node18 --> node19\n",
      "    node18 -..-> node2\n",
      "    node18 -..-> node15\n",
      "    node18 --> node20\n",
      "    node61[\"forward\"]\n",
      "    node79[\"CausalSelfAttention\"]\n",
      "    node17[\"forward\"]\n",
      "    node36[\"forward\"]\n",
      "    node42[\"forward\"]\n",
      "    node76[\"forward\"]\n",
      "    node22[\"__init__\"]\n",
      "    node28[\"SudokuEBM\"]\n",
      "    node28 -..-> node15\n",
      "    node28 --> node29\n",
      "    node28 --> node30\n",
      "    node28 -..-> node2\n",
      "    node28 -..-> node12\n",
      "    node28 -..-> node9\n",
      "    node1[\"models.py\"]\n",
      "    node1 --> node63\n",
      "    node1 --> node6\n",
      "    node1 --> node37\n",
      "    node1 --> node2\n",
      "    node1 --> node74\n",
      "    node1 --> node56\n",
      "    node1 -..-> node90\n",
      "    node1 --> node40\n",
      "    node1 --> node59\n",
      "    node1 --> node25\n",
      "    node1 --> node47\n",
      "    node1 --> node21\n",
      "    node1 -..-> node78\n",
      "    node1 --> node50\n",
      "    node1 --> node28\n",
      "    node1 --> node70\n",
      "    node1 --> node9\n",
      "    node1 --> node31\n",
      "    node1 --> node18\n",
      "    node1 --> node34\n",
      "    node1 --> node66\n",
      "    node1 --> node44\n",
      "    node1 --> node3\n",
      "    node1 --> node15\n",
      "    node1 --> node53\n",
      "    node1 --> node12\n",
      "    node77[\"randn\"]\n",
      "    node68[\"forward\"]\n",
      "    node26[\"__init__\"]\n",
      "    node26 --> node15\n",
      "    node26 --> node9\n",
      "    node26 --> node12\n",
      "    node38[\"__init__\"]\n",
      "    node38 --> node15\n",
      "    node21[\"AutoencodeModel\"]\n",
      "    node21 --> node24\n",
      "    node21 --> node23\n",
      "    node21 --> node22\n",
      "    node50[\"GNNConvEBM\"]\n",
      "    node50 --> node51\n",
      "    node50 -..-> node47\n",
      "    node50 --> node52\n",
      "    node50 -..-> node15\n",
      "    node50 -..-> node44\n",
      "    node48[\"__init__\"]\n",
      "    node54[\"__init__\"]\n",
      "    node66[\"GNNDiffusionWrapper\"]\n",
      "    node66 --> node69\n",
      "    node66 --> node68\n",
      "    node66 --> node67\n",
      "    node30[\"forward\"]\n",
      "    node30 --> node2\n",
      "    node6[\"Attend\"]\n",
      "    node6 --> node7\n",
      "    node6 --> node8\n",
      "    node56[\"GNNConv1DEBMV2\"]\n",
      "    node56 --> node58\n",
      "    node56 --> node57\n",
      "    node56 -..-> node15\n",
      "    node56 -..-> node53\n",
      "    node15[\"SinusoidalPosEmb\"]\n",
      "    node15 --> node16\n",
      "    node15 --> node17\n",
      "    node40[\"GraphReverse\"]\n",
      "    node40 --> node43\n",
      "    node40 -..-> node15\n",
      "    node40 --> node41\n",
      "    node40 --> node42\n",
      "    node40 -..-> node97\n",
      "    node45[\"__init__\"]\n",
      "    node55[\"forward\"]\n",
      "    node55 --> node2\n",
      "    node29[\"__init__\"]\n",
      "    node29 --> node15\n",
      "    node29 --> node9\n",
      "    node29 --> node12\n",
      "    node27[\"forward\"]\n",
      "    node27 --> node2\n",
      "    node97[\"LogicMachine\"]\n",
      "    node97 -..-> node92\n",
      "    node60[\"__init__\"]\n",
      "    node60 --> node15\n",
      "    node60 --> node53\n",
      "    node73[\"randn\"]\n",
      "    node58[\"forward\"]\n",
      "    node62[\"randn\"]\n",
      "    node2[\"swish\"]\n",
      "    node3[\"RMSNorm\"]\n",
      "    node3 --> node5\n",
      "    node3 --> node4\n",
      "    node20[\"forward\"]\n",
      "    node20 --> node2\n",
      "    node49[\"forward\"]\n",
      "    node49 --> node2\n",
      "    node65[\"forward\"]\n",
      "    node37[\"GraphEBM\"]\n",
      "    node37 --> node38\n",
      "    node37 --> node39\n",
      "    node37 -..-> node97\n",
      "    node37 -..-> node15\n",
      "    node24[\"forward\"]\n",
      "    node10[\"__init__\"]\n",
      "    node10 --> node3\n",
      "    node10 --> node6\n",
      "    node31[\"SudokuDenoise\"]\n",
      "    node31 --> node33\n",
      "    node31 -..-> node15\n",
      "    node31 -..-> node2\n",
      "    node31 -..-> node12\n",
      "    node31 --> node32\n",
      "    node31 -..-> node9\n",
      "    node74[\"GNNConv1DV2DiffusionWrapper\"]\n",
      "    node74 --> node76\n",
      "    node74 --> node77\n",
      "    node74 --> node75\n",
      "    node44[\"NLMConvBlock\"]\n",
      "    node44 -..-> node2\n",
      "    node44 -..-> node97\n",
      "    node44 --> node45\n",
      "    node44 --> node46\n",
      "    node52[\"forward\"]\n",
      "    node47[\"NLMConv1DBlock\"]\n",
      "    node47 --> node48\n",
      "    node47 -..-> node2\n",
      "    node47 -..-> node97\n",
      "    node47 --> node49\n",
      "    node59[\"GNNConv1DReverse\"]\n",
      "    node59 --> node61\n",
      "    node59 -..-> node15\n",
      "    node59 --> node60\n",
      "    node59 --> node62\n",
      "    node59 -..-> node53\n",
      "    node63[\"DiffusionWrapper\"]\n",
      "    node63 --> node65\n",
      "    node63 --> node64\n",
      "    node46[\"forward\"]\n",
      "    node46 --> node2\n",
      "    node34[\"SudokuTransformerEBM\"]\n",
      "    node34 --> node36\n",
      "    node34 -..-> node85\n",
      "    node34 --> node35\n",
      "    node34 -..-> node15\n",
      "    node9[\"Attention\"]\n",
      "    node9 --> node11\n",
      "    node9 -..-> node6\n",
      "    node9 -..-> node3\n",
      "    node9 --> node10\n",
      "    node92[\"LogicLayer\"]\n",
      "    node92 -..-> node91\n",
      "    node85[\"GPT\"]\n",
      "    node85 -..-> node82\n",
      "    node71[\"__init__\"]\n",
      "    node70[\"GNNConvDiffusionWrapper\"]\n",
      "    node70 --> node72\n",
      "    node70 --> node71\n",
      "    node70 --> node73\n",
      "    node75[\"__init__\"]\n",
      "    node57[\"__init__\"]\n",
      "    node57 --> node15\n",
      "    node57 --> node53\n",
      "    node12[\"ResBlock\"]\n",
      "    node12 --> node13\n",
      "    node12 -..-> node2\n",
      "    node12 --> node14\n",
      "    node43[\"randn\"]\n",
      "    node51[\"__init__\"]\n",
      "    node51 --> node47\n",
      "    node51 --> node15\n",
      "    node51 --> node44\n",
      "    node14[\"forward\"]\n",
      "    node14 --> node2\n",
      "    node67[\"__init__\"]\n",
      "    node32[\"__init__\"]\n",
      "    node32 --> node15\n",
      "    node32 --> node9\n",
      "    node32 --> node12\n",
      "    node82[\"Block\"]\n",
      "    node82 -..-> node79\n",
      "    node53[\"NLMConv1DBlockV2\"]\n",
      "    node53 -..-> node2\n",
      "    node53 --> node55\n",
      "    node53 --> node54\n",
      "    node69[\"randn\"]\n",
      "    node72[\"forward\"]\n",
      "    node8[\"forward\"]\n",
      "    node23[\"decode\"]\n",
      "    node64[\"__init__\"]\n",
      "    node91[\"_get_tuple_n\"]\n",
      "    node25[\"SudokuLatentEBM\"]\n",
      "    node25 --> node27\n",
      "    node25 -..-> node15\n",
      "    node25 -..-> node2\n",
      "    node25 --> node26\n",
      "    node25 -..-> node12\n",
      "    node25 -..-> node9\n",
      "    style node78 fill:#f9f,stroke:#333,stroke-width:2px\n",
      "    style node103 fill:#f9f,stroke:#333,stroke-width:2px\n",
      "    style node90 fill:#f9f,stroke:#333,stroke-width:2px\n",
      "    style node18 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node79 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node28 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node1 fill:#f9f,stroke:#333,stroke-width:2px\n",
      "    style node21 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node50 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node66 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node6 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node56 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node15 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node40 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node97 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node3 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node37 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node31 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node74 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node44 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node47 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node59 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node63 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node34 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node9 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node92 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node85 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node70 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node12 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node82 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node53 fill:#bbf,stroke:#333,stroke-width:2px\n",
      "    style node25 fill:#bbf,stroke:#333,stroke-width:2px\n"
     ]
    }
   ],
   "source": [
    "print(sub_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = clean_and_breakdown_mermaid_graph(graph)\n",
    "\n",
    "# visualize_function_level_graph(cg)\n",
    "cg.keys()\n",
    "\n",
    "sub_graph = cg[\"diffusion_lib/transformer.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d2py\n",
      "  Downloading d2py-0.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading d2py-0.6.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: d2py\n",
      "Successfully installed d2py-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install d2py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py-d2\n",
      "  Downloading py_d2-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading py_d2-1.0.1-py3-none-any.whl (7.3 kB)\n",
      "Installing collected packages: py-d2\n",
      "Successfully installed py-d2-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install py-d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_d2 import D2Diagram, D2Shape, D2Connection, D2Style\n",
    "\n",
    "shapes = [\n",
    "    D2Shape(name=\"shape_name1\", style=D2Style(fill=\"red\")),\n",
    "    D2Shape(name=\"shape_name2\", style=D2Style(fill=\"blue\"))]\n",
    "connections = [\n",
    "    D2Connection(shape_1=\"shape_name1\", shape_2=\"shape_name2\")\n",
    "]\n",
    "\n",
    "diagram = D2Diagram(shapes=shapes, connections=connections)\n",
    "\n",
    "with open(\"graph.d2\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(diagram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
