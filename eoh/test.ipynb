{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution Node \n",
    "- Task, Input, Output\n",
    "- LLM guided evolution\n",
    "- LLM-engineered Code Function or Prompt\n",
    "\n",
    "Note: \n",
    "* Ok to have error, as evolution is decoupled with evaluation for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# input_dict = {\"n\": 10}\n",
    "# reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # Evolution with guaranteed structural fitness\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "node = EvolNode(mp, None, None)\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "reasoning, code = node.evolve([input_dict], \"i1\", replace=True)\n",
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 31}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution Graph\n",
    "- Take care of connecting each components (unfolding dictionary object etc.)\n",
    "- Planning topology with evolution node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaPrompt I1: \n",
      "Goal: Help me date Dilireba, I'm a white colar worker living on salary.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON-style plan represented as a Directed Acyclic Graph (DAG) to achieve the goal. Use creative topology in the DAG, include parallel tasks if required.\n",
      "\n",
      "The plan should include:\n",
      "\n",
      "- **Nodes**: Each node represents a key action or step and must contain the following attributes:\n",
      "  - `task`: Description of the task.\n",
      "  - `name`: Concise name used for the task function.\n",
      "  - `input`: The resources, information, or prerequisites needed to perform the action.\n",
      "  - `output`: The immediate result or outcome of the action.\n",
      "  - `target`: The purpose or goal that the action contributes to.\n",
      "  - `mode`: The execution mode for this task (\"CODE\" or \"PROMPT\").\n",
      "\n",
      "- **Edges**: Each edge represents a dependency or relationship between nodes, indicating that one step supports or leads to another.\n",
      "  - `source`: The `id` of the source node (the preceding action).\n",
      "  - `target`: The `id` of the target node (the subsequent action).\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"task\": \"Task 1\",\n",
      "      \"name\": \"task_1\"\n",
      "      \"input\": \"Inputs required for Action 1\",\n",
      "      \"output\": \"Outputs/result of Action 1\",\n",
      "      \"target\": \"Purpose of Action 1\"\n",
      "      \"mode\": \"CODE\"\n",
      "    },\n",
      "    {\n",
      "      \"task\": \"Task 2\",\n",
      "      \"name\": \"task_2\",\n",
      "      \"input\": \"Inputs required for Action 2\",\n",
      "      \"output\": \"Outputs/result of Action 2\",\n",
      "      \"target\": \"Purpose of Action 2\",\n",
      "      \"mode\": \"PROMPT\"\n",
      "    }\n",
      "    // Add more nodes as needed\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\n",
      "      \"source\": \"task_1\",\n",
      "      \"target\": \"task_2\"\n",
      "    }\n",
      "    // Add more edges as needed\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "print(\"MetaPrompt I1: \")\n",
    "print(prompt)\n",
    "\n",
    "from methods.llm import get_openai_response\n",
    "response = get_openai_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# from methods.meta_prompt import parse_json_from_response\n",
    "\n",
    "tactic = re.findall(r\"\\{(.*)\\}\", response, re.DOTALL)\n",
    "plan_dict = extract_json_from_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<methods.eoh_evolution.EvolNode at 0x2893758d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, MetaPlan, extract_json_from_text\n",
    "from methods.eoh_evolution import EvolNode\n",
    "from methods.llm import get_openai_response as get_response\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Collect MetaPrompt from parsed Plan-Graph Response\n",
    "meta_node_prompts = []\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(task=node.get(\"task\"),  func_name=node.get(\"name\"), input=node.get(\"input\"), output=node.get(\"output\"), mode=node.get(\"mode\").lower())\n",
    "    meta_node_prompts.append(node_prompt)\n",
    "    \n",
    "edges = plan_dict[\"edges\"]\n",
    "\n",
    "EvolNode(meta_prompt = node_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EvalNode Test: \n",
    "At the beginning level, generation of EvalNode (when code is used here) should compile with success, and it should takes input and produce output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
