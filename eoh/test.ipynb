{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/evolnode.png\" width=\"800\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Evolution Node free you from coding and debugging, let LLM evolve your code for you.</em></p>\n",
    "</div>\n",
    "<div align=\"left\">\n",
    "<p><em>Bored of manual coding, a function? EvolNode let LLM automate function design and guide the evolution of it with genetic algorithm. A node here takes a task, input, and output, it uses either code or another LLM to complete the task, ensuring aligned input and output value types and ,.names.Fitness evaluation is done by running the function with a few specified test cases, the more diverse the test case, the better the evolution.\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaPrompt, PromptMode\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meoh_evolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvolNode\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Code + Compilor Task\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# node = EvolNode(mp, None, None)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Prompt + LLM Task\u001b[39;00m\n\u001b[1;32m     14\u001b[0m mp \u001b[38;5;241m=\u001b[39m MetaPrompt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet the age of a celebrity.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_celeb_age\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m], PromptMode\u001b[38;5;241m.\u001b[39mPROMPT) \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaPlan, extract_json_from_text\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_execute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_func_code, call_func_prompt\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_openai_response \u001b[38;5;28;01mas\u001b[39;00m get_response\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Dict, List\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/llm.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01manthropic\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m oai_client \u001b[38;5;241m=\u001b[39m OpenAI()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_from_path\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/types/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_stream_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageStreamEvent \u001b[38;5;28;01mas\u001b[39;00m MessageStreamEvent\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtool_use_block_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolUseBlockParam \u001b[38;5;28;01mas\u001b[39;00m ToolUseBlockParam\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_create_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageCreateParams \u001b[38;5;28;01mas\u001b[39;00m MessageCreateParams\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mraw_message_stop_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RawMessageStopEvent \u001b[38;5;28;01mas\u001b[39;00m RawMessageStopEvent\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mraw_message_delta_event\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RawMessageDeltaEvent \u001b[38;5;28;01mas\u001b[39;00m RawMessageDeltaEvent\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/anthropic/types/message_create_params.py:23\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageParam\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessageCreateParamsBase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessageCreateParamsStreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m ]\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mMessageCreateParamsBase\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mTypedDict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRequired\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"The maximum number of tokens to generate before stopping.\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43;03m    Note that our models may stop _before_ reaching this maximum. This parameter\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43;03m    [models](https://docs.anthropic.com/en/docs/models-overview) for details.\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/typing_extensions.py:850\u001b[0m, in \u001b[0;36m_TypedDictMeta.__new__\u001b[0;34m(cls, name, bases, ns, total)\u001b[0m\n\u001b[1;32m    848\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypedDict(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mf0: t0, f1: t1, ...}); each t must be a type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TAKES_MODULE:\n\u001b[0;32m--> 850\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtp_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__module__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mown_annotations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    856\u001b[0m         n: typing\u001b[38;5;241m.\u001b[39m_type_check(tp, msg)\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    858\u001b[0m     }\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/typing_extensions.py:851\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    848\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypedDict(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mf0: t0, f1: t1, ...}); each t must be a type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TAKES_MODULE:\n\u001b[1;32m    850\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 851\u001b[0m         n: \u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtp_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__module__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    853\u001b[0m     }\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     own_annotations \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    856\u001b[0m         n: typing\u001b[38;5;241m.\u001b[39m_type_check(tp, msg)\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, tp \u001b[38;5;129;01min\u001b[39;00m own_annotations\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    858\u001b[0m     }\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:186\u001b[0m, in \u001b[0;36m_type_check\u001b[0;34m(arg, msg, is_argument, module, allow_special_forms)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_argument:\n\u001b[1;32m    184\u001b[0m         invalid_generic_forms \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (Final,)\n\u001b[0;32m--> 186\u001b[0m arg \u001b[38;5;241m=\u001b[39m \u001b[43m_type_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_special_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_special_forms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(arg, _GenericAlias) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         arg\u001b[38;5;241m.\u001b[39m__origin__ \u001b[38;5;129;01min\u001b[39;00m invalid_generic_forms):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid as type argument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:164\u001b[0m, in \u001b[0;36m_type_convert\u001b[0;34m(arg, module, allow_special_forms)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mForwardRef\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_special_forms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/typing.py:857\u001b[0m, in \u001b[0;36mForwardRef.__init__\u001b[0;34m(self, arg, is_argument, module, is_class)\u001b[0m\n\u001b[1;32m    855\u001b[0m     arg_to_compile \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(arg_to_compile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<string>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward reference must be an expression -- got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# input_dict = {\"n\": 10}\n",
    "# reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # Evolution with guaranteed structural fitness\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "node = EvolNode(mp, None, None)\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "reasoning, code = node.evolve([input_dict], \"i1\", replace=True)\n",
    "node(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"1000\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaPrompt I1: \n",
      "Goal: Help me date Dilireba, I'm a white colar worker living on salary.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON-style plan represented as a Directed Acyclic Graph (DAG) to achieve the goal. Use creative topology in the DAG, include parallel tasks if required.\n",
      "\n",
      "The plan should include:\n",
      "\n",
      "- **Nodes**: Each node represents a key action or step and must contain the following attributes:\n",
      "  - `task`: Description of the task.\n",
      "  - `name`: Concise name used for the task function.\n",
      "  - `input`: The resources, information, or prerequisites needed to perform the action.\n",
      "  - `output`: The immediate result or outcome of the action.\n",
      "  - `target`: The purpose or goal that the action contributes to.\n",
      "  - `mode`: The execution mode for this task (\"CODE\" or \"PROMPT\").\n",
      "\n",
      "- **Edges**: Each edge represents a dependency or relationship between nodes, indicating that one step supports or leads to another.\n",
      "  - `source`: The `id` of the source node (the preceding action).\n",
      "  - `target`: The `id` of the target node (the subsequent action).\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"task\": \"Task 1\",\n",
      "      \"name\": \"task_1\"\n",
      "      \"input\": \"Inputs required for Action 1\",\n",
      "      \"output\": \"Outputs/result of Action 1\",\n",
      "      \"target\": \"Purpose of Action 1\"\n",
      "      \"mode\": \"CODE\"\n",
      "    },\n",
      "    {\n",
      "      \"task\": \"Task 2\",\n",
      "      \"name\": \"task_2\",\n",
      "      \"input\": \"Inputs required for Action 2\",\n",
      "      \"output\": \"Outputs/result of Action 2\",\n",
      "      \"target\": \"Purpose of Action 2\",\n",
      "      \"mode\": \"PROMPT\"\n",
      "    }\n",
      "    // Add more nodes as needed\n",
      "  ],\n",
      "  \"edges\": [\n",
      "    {\n",
      "      \"source\": \"task_1\",\n",
      "      \"target\": \"task_2\"\n",
      "    }\n",
      "    // Add more edges as needed\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "print(\"MetaPrompt I1: \")\n",
    "print(prompt)\n",
    "\n",
    "from methods.llm import get_openai_response\n",
    "response = get_openai_response(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# from methods.meta_prompt import parse_json_from_response\n",
    "\n",
    "tactic = re.findall(r\"\\{(.*)\\}\", response, re.DOTALL)\n",
    "plan_dict = extract_json_from_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<methods.eoh_evolution.EvolNode at 0x2893758d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, MetaPlan, extract_json_from_text\n",
    "from methods.eoh_evolution import EvolNode\n",
    "from methods.llm import get_openai_response as get_response\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# Collect MetaPrompt from parsed Plan-Graph Response\n",
    "meta_node_prompts = []\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(task=node.get(\"task\"),  func_name=node.get(\"name\"), input=node.get(\"input\"), output=node.get(\"output\"), mode=node.get(\"mode\").lower())\n",
    "    meta_node_prompts.append(node_prompt)\n",
    "    \n",
    "edges = plan_dict[\"edges\"]\n",
    "\n",
    "EvolNode(meta_prompt = node_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RepoRAG\n",
    "* Smooth Dependency Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo already cloned, skipping cloning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "success: successfully compiled d2_output/evolve_graph_0.d2 to d2_output/evolve_graph_0.png in 688.717624ms\n",
      "success: successfully compiled d2_output/evolve_graph_1.d2 to d2_output/evolve_graph_1.png in 551.04575ms\n",
      "success: successfully compiled d2_output/evolve_graph_2.d2 to d2_output/evolve_graph_2.png in 530.829375ms\n",
      "success: successfully compiled d2_output/evolve_graph_3.d2 to d2_output/evolve_graph_3.png in 526.930417ms\n",
      "success: successfully compiled d2_output/evolve_graph_4.d2 to d2_output/evolve_graph_4.png in 528.646584ms\n",
      "success: successfully compiled d2_output/evolve_graph_5.d2 to d2_output/evolve_graph_5.png in 573.277125ms\n",
      "success: successfully compiled d2_output/evolve_graph_6.d2 to d2_output/evolve_graph_6.png in 524.445167ms\n",
      "success: successfully compiled d2_output/evolve_graph_7.d2 to d2_output/evolve_graph_7.png in 505.692208ms\n",
      "success: successfully compiled d2_output/evolve_graph_8.d2 to d2_output/evolve_graph_8.png in 511.190582ms\n",
      "success: successfully compiled d2_output/evolve_graph_9.d2 to d2_output/evolve_graph_9.png in 516.543292ms\n",
      "success: successfully compiled d2_output/evolve_graph_10.d2 to d2_output/evolve_graph_10.png in 540.215292ms\n",
      "success: successfully compiled d2_output/evolve_graph_11.d2 to d2_output/evolve_graph_11.png in 523.641209ms\n",
      "success: successfully compiled d2_output/evolve_graph_12.d2 to d2_output/evolve_graph_12.png in 515.868792ms\n",
      "success: successfully compiled d2_output/evolve_graph_13.d2 to d2_output/evolve_graph_13.png in 518.15675ms\n",
      "success: successfully compiled d2_output/evolve_graph_14.d2 to d2_output/evolve_graph_14.png in 524.987459ms\n",
      "success: successfully compiled d2_output/evolve_graph_15.d2 to d2_output/evolve_graph_15.png in 514.149917ms\n",
      "success: successfully compiled d2_output/evolve_graph_16.d2 to d2_output/evolve_graph_16.png in 525.933083ms\n",
      "success: successfully compiled d2_output/evolve_graph_17.d2 to d2_output/evolve_graph_17.png in 518.454916ms\n",
      "success: successfully compiled d2_output/evolve_graph_18.d2 to d2_output/evolve_graph_18.png in 560.795167ms\n",
      "success: successfully compiled d2_output/evolve_graph_19.d2 to d2_output/evolve_graph_19.png in 554.915459ms\n",
      "success: successfully compiled d2_output/evolve_graph_20.d2 to d2_output/evolve_graph_20.png in 581.815708ms\n",
      "success: successfully compiled d2_output/evolve_graph_21.d2 to d2_output/evolve_graph_21.png in 547.716084ms\n",
      "success: successfully compiled d2_output/evolve_graph_22.d2 to d2_output/evolve_graph_22.png in 537.779875ms\n",
      "success: successfully compiled d2_output/evolve_graph_23.d2 to d2_output/evolve_graph_23.png in 597.751375ms\n",
      "success: successfully compiled d2_output/evolve_graph_24.d2 to d2_output/evolve_graph_24.png in 570.974708ms\n",
      "success: successfully compiled d2_output/evolve_graph_25.d2 to d2_output/evolve_graph_25.png in 570.184293ms\n",
      "success: successfully compiled d2_output/evolve_graph_26.d2 to d2_output/evolve_graph_26.png in 566.610292ms\n",
      "success: successfully compiled d2_output/evolve_graph_27.d2 to d2_output/evolve_graph_27.png in 568.480333ms\n",
      "success: successfully compiled d2_output/evolve_graph_28.d2 to d2_output/evolve_graph_28.png in 572.443917ms\n",
      "success: successfully compiled d2_output/evolve_graph_29.d2 to d2_output/evolve_graph_29.png in 549.059583ms\n",
      "success: successfully compiled d2_output/evolve_graph_30.d2 to d2_output/evolve_graph_30.png in 582.06125ms\n",
      "success: successfully compiled d2_output/evolve_graph_31.d2 to d2_output/evolve_graph_31.png in 573.514875ms\n",
      "success: successfully compiled d2_output/evolve_graph_32.d2 to d2_output/evolve_graph_32.png in 590.582417ms\n",
      "success: successfully compiled d2_output/evolve_graph_33.d2 to d2_output/evolve_graph_33.png in 600.324542ms\n",
      "success: successfully compiled d2_output/evolve_graph_34.d2 to d2_output/evolve_graph_34.png in 575.083874ms\n",
      "success: successfully compiled d2_output/evolve_graph_35.d2 to d2_output/evolve_graph_35.png in 572.966542ms\n",
      "success: successfully compiled d2_output/evolve_graph_36.d2 to d2_output/evolve_graph_36.png in 623.435625ms\n",
      "success: successfully compiled d2_output/evolve_graph_37.d2 to d2_output/evolve_graph_37.png in 627.033959ms\n",
      "success: successfully compiled d2_output/evolve_graph_38.d2 to d2_output/evolve_graph_38.png in 626.627875ms\n",
      "success: successfully compiled d2_output/evolve_graph_39.d2 to d2_output/evolve_graph_39.png in 627.643834ms\n",
      "success: successfully compiled d2_output/evolve_graph_40.d2 to d2_output/evolve_graph_40.png in 625.883416ms\n",
      "success: successfully compiled d2_output/evolve_graph_41.d2 to d2_output/evolve_graph_41.png in 622.849292ms\n",
      "success: successfully compiled d2_output/evolve_graph_42.d2 to d2_output/evolve_graph_42.png in 663.517833ms\n",
      "success: successfully compiled d2_output/evolve_graph_43.d2 to d2_output/evolve_graph_43.png in 649.932042ms\n",
      "success: successfully compiled d2_output/evolve_graph_44.d2 to d2_output/evolve_graph_44.png in 656.906708ms\n",
      "success: successfully compiled d2_output/evolve_graph_45.d2 to d2_output/evolve_graph_45.png in 650.935375ms\n",
      "success: successfully compiled d2_output/evolve_graph_46.d2 to d2_output/evolve_graph_46.png in 657.302416ms\n",
      "success: successfully compiled d2_output/evolve_graph_47.d2 to d2_output/evolve_graph_47.png in 651.271625ms\n",
      "success: successfully compiled d2_output/evolve_graph_48.d2 to d2_output/evolve_graph_48.png in 673.121875ms\n",
      "success: successfully compiled d2_output/evolve_graph_49.d2 to d2_output/evolve_graph_49.png in 721.237375ms\n",
      "success: successfully compiled d2_output/evolve_graph_50.d2 to d2_output/evolve_graph_50.png in 728.206042ms\n",
      "success: successfully compiled d2_output/evolve_graph_51.d2 to d2_output/evolve_graph_51.png in 730.000709ms\n",
      "success: successfully compiled d2_output/evolve_graph_52.d2 to d2_output/evolve_graph_52.png in 726.282166ms\n",
      "success: successfully compiled d2_output/evolve_graph_53.d2 to d2_output/evolve_graph_53.png in 714.084041ms\n",
      "success: successfully compiled d2_output/evolve_graph_54.d2 to d2_output/evolve_graph_54.png in 721.532458ms\n",
      "success: successfully compiled d2_output/evolve_graph_55.d2 to d2_output/evolve_graph_55.png in 721.986666ms\n",
      "success: successfully compiled d2_output/evolve_graph_56.d2 to d2_output/evolve_graph_56.png in 714.533126ms\n",
      "success: successfully compiled d2_output/evolve_graph_57.d2 to d2_output/evolve_graph_57.png in 715.8715ms\n",
      "success: successfully compiled d2_output/evolve_graph_58.d2 to d2_output/evolve_graph_58.png in 757.139334ms\n",
      "success: successfully compiled d2_output/evolve_graph_59.d2 to d2_output/evolve_graph_59.png in 719.509375ms\n",
      "success: successfully compiled d2_output/evolve_graph_60.d2 to d2_output/evolve_graph_60.png in 762.038625ms\n",
      "success: successfully compiled d2_output/evolve_graph_61.d2 to d2_output/evolve_graph_61.png in 715.007918ms\n",
      "success: successfully compiled d2_output/evolve_graph_62.d2 to d2_output/evolve_graph_62.png in 732.640792ms\n",
      "success: successfully compiled d2_output/evolve_graph_63.d2 to d2_output/evolve_graph_63.png in 751.626166ms\n",
      "success: successfully compiled d2_output/evolve_graph_64.d2 to d2_output/evolve_graph_64.png in 723.542292ms\n",
      "success: successfully compiled d2_output/evolve_graph_65.d2 to d2_output/evolve_graph_65.png in 748.25575ms\n",
      "success: successfully compiled d2_output/evolve_graph_66.d2 to d2_output/evolve_graph_66.png in 747.521166ms\n",
      "success: successfully compiled d2_output/evolve_graph_67.d2 to d2_output/evolve_graph_67.png in 724.502625ms\n",
      "success: successfully compiled d2_output/evolve_graph_68.d2 to d2_output/evolve_graph_68.png in 723.209583ms\n",
      "success: successfully compiled d2_output/evolve_graph_69.d2 to d2_output/evolve_graph_69.png in 717.329125ms\n",
      "success: successfully compiled d2_output/evolve_graph_70.d2 to d2_output/evolve_graph_70.png in 719.220625ms\n",
      "success: successfully compiled d2_output/evolve_graph_71.d2 to d2_output/evolve_graph_71.png in 719.724208ms\n",
      "success: successfully compiled d2_output/evolve_graph_72.d2 to d2_output/evolve_graph_72.png in 712.919833ms\n",
      "success: successfully compiled d2_output/evolve_graph_73.d2 to d2_output/evolve_graph_73.png in 739.832916ms\n",
      "success: successfully compiled d2_output/evolve_graph_74.d2 to d2_output/evolve_graph_74.png in 713.694333ms\n",
      "success: successfully compiled d2_output/evolve_graph_75.d2 to d2_output/evolve_graph_75.png in 723.052083ms\n",
      "success: successfully compiled d2_output/evolve_graph_76.d2 to d2_output/evolve_graph_76.png in 713.130125ms\n",
      "success: successfully compiled d2_output/evolve_graph_77.d2 to d2_output/evolve_graph_77.png in 723.543501ms\n",
      "success: successfully compiled d2_output/evolve_graph_78.d2 to d2_output/evolve_graph_78.png in 721.523166ms\n",
      "success: successfully compiled d2_output/evolve_graph_79.d2 to d2_output/evolve_graph_79.png in 728.088375ms\n",
      "success: successfully compiled d2_output/evolve_graph_80.d2 to d2_output/evolve_graph_80.png in 717.992958ms\n",
      "success: successfully compiled d2_output/evolve_graph_81.d2 to d2_output/evolve_graph_81.png in 726.026333ms\n",
      "success: successfully compiled d2_output/evolve_graph_82.d2 to d2_output/evolve_graph_82.png in 743.068459ms\n",
      "success: successfully compiled d2_output/evolve_graph_83.d2 to d2_output/evolve_graph_83.png in 722.534875ms\n",
      "success: successfully compiled d2_output/evolve_graph_84.d2 to d2_output/evolve_graph_84.png in 719.859626ms\n",
      "success: successfully compiled d2_output/evolve_graph_85.d2 to d2_output/evolve_graph_85.png in 728.60975ms\n",
      "success: successfully compiled d2_output/evolve_graph_86.d2 to d2_output/evolve_graph_86.png in 736.503916ms\n",
      "success: successfully compiled d2_output/evolve_graph_87.d2 to d2_output/evolve_graph_87.png in 725.965501ms\n",
      "success: successfully compiled d2_output/evolve_graph_88.d2 to d2_output/evolve_graph_88.png in 730.041251ms\n",
      "success: successfully compiled d2_output/evolve_graph_89.d2 to d2_output/evolve_graph_89.png in 726.096249ms\n",
      "success: successfully compiled d2_output/evolve_graph_90.d2 to d2_output/evolve_graph_90.png in 735.007208ms\n",
      "success: successfully compiled d2_output/evolve_graph_91.d2 to d2_output/evolve_graph_91.png in 725.929333ms\n",
      "success: successfully compiled d2_output/evolve_graph_92.d2 to d2_output/evolve_graph_92.png in 726.458417ms\n",
      "success: successfully compiled d2_output/evolve_graph_93.d2 to d2_output/evolve_graph_93.png in 718.309833ms\n",
      "success: successfully compiled d2_output/evolve_graph_94.d2 to d2_output/evolve_graph_94.png in 726.8805ms\n",
      "success: successfully compiled d2_output/evolve_graph_95.d2 to d2_output/evolve_graph_95.png in 723.444709ms\n",
      "success: successfully compiled d2_output/evolve_graph_96.d2 to d2_output/evolve_graph_96.png in 716.166667ms\n",
      "success: successfully compiled d2_output/evolve_graph_97.d2 to d2_output/evolve_graph_97.png in 723.200541ms\n",
      "success: successfully compiled d2_output/evolve_graph_98.d2 to d2_output/evolve_graph_98.png in 743.516ms\n",
      "success: successfully compiled d2_output/evolve_graph_99.d2 to d2_output/evolve_graph_99.png in 736.355875ms\n",
      "Creating GIF: 100%|██████████| 100/100 [00:26<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tools.repo import *\n",
    "\n",
    "# (I). Pick top growing repo\n",
    "# fastest_repos = get_fastest_growing_repos(days_ago=14, top_n = 50, print=False)\n",
    "# repo_url = fastest_repos[0]['html_url']\n",
    "\n",
    "# (I). Build a GIF of file-dependency of a git repo\n",
    "repo_url = \"https://github.com/xjdr-alt/entropix.git\"\n",
    "temp_repo = \"entropix_repo\"\n",
    "\n",
    "file_graph = create_gif_from_repo(repo_url, temp_repo, frame_count=60, fps = 10, output_name=\"entropix_repo_evolution\")\n",
    "\n",
    "# (II). Build function-level dependency graph of a module within the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number of objects in the subgraph: 15\n"
     ]
    }
   ],
   "source": [
    "# (II). Build function-level dependency graph of a module within the repo\n",
    "from tools.repo import *\n",
    "\n",
    "temp_repo = \"hdcnn\" # Contains an interesting new DL model architecture's implementation\n",
    "\n",
    "python_files = get_python_files(temp_repo) # get all python files \n",
    "\n",
    "start_file = python_files[0] # pick the first one for debugging purpose \n",
    "\n",
    "dag = build_cross_file_dag(temp_repo, start_file)\n",
    "\n",
    "name_map = {dag[k][\"name\"]: k for k in dag} # Map name to node-id for all nodes in the DAG\n",
    "\n",
    "pick_object = list(name_map.keys())[0] # pick the first object from 'start_file'\n",
    "\n",
    "sub_dag = extract_subgraph_dag(dag, name_map[pick_object], depth=6) # Extact depedency graph starting from pick_object\n",
    "\n",
    "sub_dag = decide_opacity_of_dag(sub_dag, progress=1.0, cap_node_number=30) # limit number of nodes for easy understanding\n",
    "\n",
    "# func_graph = create_evolution_gif(sub_dag, frame_count=60, fps=10) # Sick Animation once again ...\n",
    "# visualize_dag(sub_dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found class method with name:  HDComputing::superpose\n",
      "def superpose(self, hvs):\n",
      "    sum_hv = np.sum(hvs, axis=0)\n",
      "    return np.sign(sum_hv)\n"
     ]
    }
   ],
   "source": [
    "from tools.repo import read_node_content\n",
    "\n",
    "node_content = read_node_content(sub_dag['node9'])\n",
    "\n",
    "print(node_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n",
      "Found class method with name:  HDComputing::superpose\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_claude_response # <-- this is the LLM we will be using for summarization\n",
    "from tools.repo import get_summary_and_code\n",
    "\n",
    "summary_str, code_str = get_summary_and_code(sub_dag['node9'], get_claude_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BreakDown on Task (When something is hard, we break it down)\n",
    "\n",
    "# 1. Construct step-wise PNG\n",
    "#    - transparency changing function\n",
    "#    - growing strategy (code-based subnodes as importance score)\n",
    "# 2. Animate into GIF (not perfect due to scale disconnection)\n",
    "\n",
    "\n",
    "# 3. Agent to understand codebase with repo-DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
