{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/evolnode.png\" width=\"800\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Evolution Node free you from coding and debugging, let LLM evolve your code for you.</em></p>\n",
    "</div>\n",
    "<div align=\"left\">\n",
    "<p><em>Bored of manual coding, a function? EvolNode let LLM automate function design and guide the evolution of it with genetic algorithm. A node here takes a task, input, and output, it uses either code or another LLM to complete the task, ensuring aligned input and output value types and ,.names.Fitness evaluation is done by running the function with a few specified test cases, the more diverse the test case, the better the evolution.\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.eoh_evolution import EvolNode\n",
    "\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Generate Fibonacci sequence.\", \"fibonacci\", [\"n\"], [\"sequence\"], [\"int\"], [\"list\"], PromptMode.CODE) # \n",
    "# node = EvolNode(mp, None, None)\n",
    "# input_dict = {\"n\": 10}\n",
    "# reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # Evolution with guaranteed structural fitness\n",
    "# node(input_dict) # Ok we need a output dictionary here as well ...\n",
    "\n",
    "\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "node = EvolNode(mp, None, None)\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "reasoning, code = node.evolve([input_dict], \"i1\", replace=True) # evolution node assume access to 'test_cases', evalnode should contain those\n",
    "output_dict = node(input_dict) # LLM-is stochastic, so chances of mal-functioning here ... (Aim to resolve with massive inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test cases:  90%|█████████ | 90/100 [01:32<00:10,  1.03s/case]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "JsonDecodeError : \nExpecting property name enclosed in double quotes: line 2 column 9 (char 10)AstLiteralError : \n'{' was never closed (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# node._extend_test_cases(10) # tested fine \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_test_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:71\u001b[0m, in \u001b[0;36mEvolNode.get_test_cases\u001b[0;34m(self, num_cases)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m num_cases \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cases):\n\u001b[1;32m     70\u001b[0m         generate_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(batch_case_amount, num_cases \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cases))\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_test_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_amount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(generate_amount)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cases\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/eoh_evolution.py:47\u001b[0m, in \u001b[0;36mEvolNode._extend_test_cases\u001b[0;34m(self, num_cases)\u001b[0m\n\u001b[1;32m     43\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response(eval_prompt)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_response \u001b[38;5;241m=\u001b[39m response \u001b[38;5;66;03m# added info for debugging\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m test_case_list \u001b[38;5;241m=\u001b[39m \u001b[43mextract_json_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_cases\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mmap\u001b[39m(get_input_output_from_dict, test_case_list))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_test_cases()\n",
      "File \u001b[0;32m~/Implementation/heuristic-search/eoh/methods/meta_prompt.py:406\u001b[0m, in \u001b[0;36mextract_json_from_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    404\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAstLiteralError : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: JsonDecodeError : \nExpecting property name enclosed in double quotes: line 2 column 9 (char 10)AstLiteralError : \n'{' was never closed (<unknown>, line 1)"
     ]
    }
   ],
   "source": [
    "# node._extend_test_cases(10) # tested fine \n",
    "\n",
    "node.get_test_cases(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, ast \n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Extracts a JSON object from a text containing either a JSON code block or a JSON-like structure.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text containing the JSON code block or JSON-like structure.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The parsed JSON object.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If no JSON structure is found or JSON is invalid.\n",
    "    \"\"\"\n",
    "    # Available Patterns\n",
    "    code_json_pattern = r'```json\\s*(\\{.*?\\})\\s*```'\n",
    "    code_python_pattern = r'```python\\s*(.*?)\\s*```'\n",
    "    json_list_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    json_dict_pattern = r'\\{[^}]+\\}'\n",
    "    \n",
    "    code_json_match = re.search(code_json_pattern, text, re.DOTALL)\n",
    "    code_python_match = re.search(code_python_pattern, text, re.DOTALL)\n",
    "    list_match = re.search(json_list_pattern, text, re.DOTALL)\n",
    "    dict_match = re.search(json_dict_pattern, text, re.DOTALL)\n",
    "    \n",
    "    if code_json_match:\n",
    "        json_str = code_json_match.group(1)\n",
    "    elif code_python_match:\n",
    "        json_str = code_python_match.group(1)\n",
    "    elif list_match:\n",
    "        json_str = list_match.group(1)\n",
    "    elif dict_match:\n",
    "        json_str = dict_match.group(0)\n",
    "    else:\n",
    "        raise ValueError(\"No JSON structure found in the provided text.\")\n",
    "          \n",
    "    # return json_str\n",
    "    # json_str = json_str.replace(\"'\", '\"')\n",
    "    error_msg = \"\"\n",
    "    try:\n",
    "        json_data = json.loads(json_str)\n",
    "        return json_data \n",
    "    except json.JSONDecodeError as e:\n",
    "        error_msg += f\"JsonDecodeError : \\n{e}\"\n",
    "    try:\n",
    "        json_data = ast.literal_eval(json_str)\n",
    "        return json_data\n",
    "    except Exception as e:\n",
    "        error_msg += f\"AstLiteralError : \\n{e}\"\n",
    "        \n",
    "    raise ValueError(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': {'name': 'Taylor Swift'}, 'expected_output': {'age': 33}},\n",
       " {'input': {'name': 'Morgan Freeman'}, 'expected_output': {'age': 86}},\n",
       " {'input': {'name': 'Billie Eilish'}, 'expected_output': {'age': 21}},\n",
       " {'input': {'name': 'Elvis Presley'}, 'expected_output': {'age': -1}},\n",
       " {'input': {'name': 'Emma Watson'}, 'expected_output': {'age': 33}},\n",
       " {'input': {'name': 'LeBron James'}, 'expected_output': {'age': 38}},\n",
       " {'input': {'name': 'Albert Einstein'}, 'expected_output': {'age': -1}},\n",
       " {'input': {'name': 'Zendaya'}, 'expected_output': {'age': 27}},\n",
       " {'input': {'name': 'Samuel L. Jackson'}, 'expected_output': {'age': 74}},\n",
       " {'input': {'name': 'Invalid Name'}, 'expected_output': {'age': -1}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_json_from_text(node.temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_python_match = re.search(code_python_pattern, r, re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': {'name': 'Taylor Swift'}, 'expected_output': {'age': 33}},\n",
       " {'input': {'name': 'Morgan Freeman'}, 'expected_output': {'age': 86}},\n",
       " {'input': {'name': 'Billie Eilish'}, 'expected_output': {'age': 21}},\n",
       " {'input': {'name': 'Elvis Presley'}, 'expected_output': {'age': -1}},\n",
       " {'input': {'name': 'Emma Watson'}, 'expected_output': {'age': 33}},\n",
       " {'input': {'name': 'LeBron James'}, 'expected_output': {'age': 38}},\n",
       " {'input': {'name': 'Albert Einstein'}, 'expected_output': {'age': -1}},\n",
       " {'input': {'name': 'Zendaya'}, 'expected_output': {'age': 27}},\n",
       " {'input': {'name': 'Samuel L. Jackson'}, 'expected_output': {'age': 74}},\n",
       " {'input': {'name': 'Invalid Name'}, 'expected_output': {'age': -1}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\n",
    "        'input': {'name': 'Taylor Swift'},\n",
    "        'expected_output': {'age': 33}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Morgan Freeman'},\n",
    "        'expected_output': {'age': 86}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Billie Eilish'},\n",
    "        'expected_output': {'age': 21}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Elvis Presley'},\n",
    "        'expected_output': {'age': -1}  # Edge case: Celebrity who has passed away\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Emma Watson'},\n",
    "        'expected_output': {'age': 33}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'LeBron James'},\n",
    "        'expected_output': {'age': 38}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Albert Einstein'},\n",
    "        'expected_output': {'age': -1}  # Edge case: Historical figure\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Zendaya'},\n",
    "        'expected_output': {'age': 27}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Samuel L. Jackson'},\n",
    "        'expected_output': {'age': 74}\n",
    "    },\n",
    "    {\n",
    "        'input': {'name': 'Invalid Name'},\n",
    "        'expected_output': {'age': -1}  # Edge case: Unrecognized name\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Evaluation TestCases\n",
    "from methods.llm import get_openai_response \n",
    "from methods.meta_prompt import extract_json_from_text \n",
    "\n",
    "eval_prompt = mp._get_eval_prompt()\n",
    "response = get_openai_response(eval_prompt)\n",
    "test_case_list = extract_json_from_text(response)\n",
    "node.test_cases.extend([(d['input'], d['expected_output']) for d in test_case_list]) # bet it's a list\n",
    "\n",
    "# Slot eval_dict into EvolNode.test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_list = extract_json_from_text(response)\n",
    "\n",
    "node.test_cases.extend([(d['input'], d['expected_output']) for d in test_case_list]) # bet it's a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'name': 'Taylor Swift'}, {'age': 33}),\n",
       " ({'name': 'Will Smith'}, {'age': 55}),\n",
       " ({'name': 'Marilyn Monroe'}, {'age': 97}),\n",
       " ({'name': 'Jaden Smith'}, {'age': 25}),\n",
       " ({'name': 'Queen Elizabeth II'}, {'age': 97})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"1000\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> But how do we know what are the tasks suitable for our goal? Design of tasks topology is the fundation of planning, let's ask LLM for help on this, too! Evolution Graph autuomate planning by imagning topology of tasks which works best for your goal.</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPlan, extract_json_from_text\n",
    "from methods.llm import get_openai_response\n",
    "from methods.diagram import visualize_plan_dict\n",
    "\n",
    "# Breaking Down EvolGraph.generate() function components here \n",
    "\n",
    "# Step 1: Generate Plan Dict\n",
    "mp = MetaPlan(\"Help me date Dilireba, I'm a white colar worker living on salary.\")\n",
    "prompt = mp._get_prompt_i1()\n",
    "response = get_openai_response(prompt)\n",
    "plan_dict = extract_json_from_text(response)\n",
    "# visualize_plan_dict(plan_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Node is critical here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Node \n",
    "get_response = get_openai_response \n",
    "\n",
    "\n",
    "prompt_content = mp._get_eval_prompt_i1()\n",
    "response = get_response(prompt_content)\n",
    "eval_dict = extract_json_from_text(response)\n",
    "\n",
    "\n",
    "# eval_prompt = MetaPrompt(\n",
    "#     task=node.get(\"task\"),\n",
    "#     func_name=node.get(\"name\"),\n",
    "#     inputs=node.get(\"input\"),\n",
    "#     outputs=node.get(\"output\"),\n",
    "#     mode=node.get(\"mode\").lower()\n",
    "# )\n",
    "# eval_node = EvolNode(meta_prompt=eval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: Evaluating wether the goal Help me date Dilireba, I'm a white colar worker living on salary. has been achieved.\n",
      "First, describe the intuition for your tactics and main steps in one sentence. The description must be inside a brace.\n",
      "Generate a JSON response describing a task to evaluate whehter the goal is completed.\n",
      "\n",
      "**Output Format:**\n",
      "\n",
      "Provide the output in the following JSON structure:\n",
      "```json\n",
      "{\n",
      "    \"task\": \"Evaluate Task\",\n",
      "    \"name\": \"eval_goal\",\n",
      "    \"input\": \"Inputs required for evaluation\",\n",
      "    \"output\": \"Outputs required for evaluation\",\n",
      "    \"target\": \"Purpose of the evaluation\",\n",
      "    \"mode: \"CODE\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "for node in plan_dict[\"nodes\"]:\n",
    "    node_prompt = MetaPrompt(\n",
    "        task=node.get(\"task\"),\n",
    "        func_name=node.get(\"name\"),\n",
    "        inputs=node.get(\"inputs\"),\n",
    "        outputs=node.get(\"outputs\"),\n",
    "        input_types=node.get(\"input_types\"),\n",
    "        output_types=node.get(\"output_types\"),\n",
    "        mode=node.get(\"mode\").lower()\n",
    "    )\n",
    "    nodes[node.get(\"name\")] = EvolNode(meta_prompt=node_prompt)\n",
    "\n",
    "edges = plan_dict[\"edges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.eoh_evolution import EvolGraph\n",
    "\n",
    "eg = EvolGraph.read_from_dict(plan_dict)\n",
    "# eg.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EvolGraph.generate() missing 1 required positional argument: 'goal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: EvolGraph.generate() missing 1 required positional argument: 'goal'"
     ]
    }
   ],
   "source": [
    "eg.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
