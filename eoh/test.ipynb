{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"left\">\n",
    "  <img src=\"img/abstract.png\" width=\"400\" alt=\"Funny little diagram\">\n",
    "  <p><em> Evolve nodes, evolve plans, and learn from the best performing ones.</em></p>\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "</em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Initialization (Refactoring ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_async_vllm_endpoint\n",
    "import os \n",
    "\n",
    "# Unlimited LLM endpoints\n",
    "endpoint_id = \"vllm-4zlipkz4iqdixa\"\n",
    "api_key = \"rpa_EPOJED42G59S80Y6SKMCOI330EQU4JPPMKV2UD2W7j0uku\"\n",
    "get_endpoint_response = get_async_vllm_endpoint(endpoint_id, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:17<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 17.10s, 0 errors\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:30<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 30.59s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 0.00s, 0 errors\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.33\n",
      "  üéØ Functional fitness: 1.00\n",
      "  ‚≠ê Global fitness:     0.67\n",
      "  üîÑ Compiled solutions:        16\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.44s\n",
      "     :: Evolution time: 17.13s\n",
      "     :: Evaluation time: 85.85s\n",
      "     :: Total time: 107.42s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "list index out of range\n",
      "list index out of range\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 66.7%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot access local variable 'age' where it is not associated with a value\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 3: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 4: Fitness: 66.7%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 5: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'celebrities': {'Dilireba': 1992, 'Fan Bingbing': 1973, 'Zhang Ziyi': 1979, 'Liu Yifei': 1987, 'Li Bingbing': 1973}}, Error message: Key age not found in prediction output\n",
      "\n",
      "\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 6: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Unknown string format: \"title\": \"Dilraba Dilmurat - Age, Family, Bio | Famous Birthdays\",\n",
      "Unknown string format: \"title\": \"Cheng Xiao - Age, Family, Bio | Famous Birthdays\",\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 7: Fitness: 16.7%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'age': 31}, Error message: \n",
      "Value mismatch for key age: 31 != 32\n",
      "\n",
      "\n",
      "Input: {'name': 'ChengXiao'}, prediction is not aligned with expected output, Expected: {'age': 26} Predicted: {'name': 'ChengXiao'}, Error message: Key age not found in prediction output\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 8: Fitness: 66.7%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'ChengXiao'}, prediction is not aligned with expected output, Expected: {'age': 26} Predicted: {'title': 'Cheng Xiao (WJSN) profile, age & facts (2024 updated) | kpopping', 'link': 'https://kpopping.com/profiles/idol/Cheng-Xiao', 'snippet': 'Cheng Xiao is a Chinese singer and actress under Yue Hua Entertainment. She is a former member of the girl group WJSN and a former member of the project...', 'position': 5}, Error message: Key age not found in prediction output\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 9: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'name' is not defined\n",
      "name 'name' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 10: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'age': 28}, Error message: \n",
      "Value mismatch for key age: 28 != 32\n",
      "\n",
      "\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 11: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "closing parenthesis '}' does not match opening parenthesis '(' (<unknown>, line 26)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)AstLiteralError : \n",
      "'{' was never closed (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 12: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 2 column 12 (char 13)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 2)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 13: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'query': 'Dilireba'}, Error message: Key age not found in prediction output\n",
      "\n",
      "\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 14: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "string indices must be integers, not 'str'\n",
      "string indices must be integers, not 'str'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 15: Fitness: 41.7%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'age': 1}, Error message: \n",
      "Value mismatch for key age: 1 != 32\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Given the Google search results for 'Dilireba', {input}, extract the age of the person mentioned. Make sure the output is a JSON string in markdown like this {'age':<value>} near the top of your response or people will die.\n",
      "\n",
      "Search results:\n",
      "{\n",
      "  \"Search Result\": [\n",
      "    {\n",
      "      \"title\": \"Dilraba Dilmurat - Wikipedia\",\n",
      "      \"link\": \"https://en.wikipedia.org/wiki/Dilraba_Dilmurat\",\n",
      "      \"snippet\": \"Dilraba Dilmurat (Uyghur: \\u062f\\u0649\\u0644\\u0631\\u06d5\\u0628\\u0627 \\u062f\\u0649\\u0644\\u0645\\u06c7\\u0631\\u0627\\u062a, Chinese: \\u8fea\\u4e3d\\u70ed\\u5df4\\u00b7\\u8fea\\u529b\\u6728\\u62c9\\u63d0; born June 3, 1992) is a Chinese actress, singer and model. She is an ethnic Uyghur ...\",\n",
      "      \"position\": 1\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Dilraba Dilmurat (\\u8fea\\u4e3d\\u70ed\\u5df4) - MyDramaList\",\n",
      "      \"link\": \"https://mydramalist.com/people/7830-dilmurat-dilraba\",\n",
      "      \"snippet\": \"Dilraba Dilmurat, born in Xinjiang, China, is an award-winning actor, dancer and singer of Uyghur descent.\",\n",
      "      \"sitelinks\": [\n",
      "        {\n",
      "          \"title\": \"Love Beyond the Grave\",\n",
      "          \"link\": \"https://mydramalist.com/750689-bai-ri-ti-deng\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Love on the Turquoise Land\",\n",
      "          \"link\": \"https://mydramalist.com/702977-xiao-qi-qing-rang\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Sword Rose\",\n",
      "          \"link\": \"https://mydramalist.com/747105-li-jian-mei-gui\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Hot Girl (2016)\",\n",
      "          \"link\": \"https://mydramalist.com/17245-hot-girl\"\n",
      "        }\n",
      "      ],\n",
      "      \"position\": 2\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Dilireba Dilmurat Profile Updated! - Kpop Profiles\",\n",
      "      \"link\": \"https://escoletadelmas.com/dilraba-dilmurat-8\",\n",
      "      \"snippet\": \"Dilraba Dilmurat Facts: \\u2013 Her fans are called Ai Li Si or Alice \\u7231\\u4e3d\\u4e1d \\u2013 She has nicknames like Xiao Di\\u5c0f\\u8fea and Chubby Di \\u80d6\\u8fea, \\u2013 Dilireba ...\",\n",
      "      \"position\": 3\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Dilraba Updates \\u8fea\\u4e3d\\u70ed\\u5df4(@dilireba_) / X\",\n",
      "      \"link\": \"https://x.com/dilireba_\",\n",
      "      \"snippet\": \"#Dilireba's studio shares her April 2024 schedule 18-19 April - Variety recording 27 April- Brand event The rest of the time will be spent filming, ...\",\n",
      "      \"position\": 4\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"(@alwaysdilraba) / X\",\n",
      "      \"link\": \"https://twitter.com/alwaysdilraba?lang=en\",\n",
      "      \"snippet\": \"For the queen of our hearts, dilraba dilmurat \\u2728 #dilraba #dilireba #\\u8fea\\u4e3d\\u70ed\\u5df4 #dilrabadilmurat reba's universe \\ud83d\\udc83\\ud83c\\udffb instagram.com/for_dilraba/\",\n",
      "      \"position\": 5\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"\\u1d05\\u026a\\u029f\\u026a\\u0280\\u1d07\\u0299\\u1d00 - Facebook\",\n",
      "      \"link\": \"https://www.facebook.com/dilirebaph/\",\n",
      "      \"snippet\": \"\\u1d05\\u026a\\u029f\\u026a\\u0280\\u1d07\\u0299\\u1d00. 22005 likes \\u00b7 3164 talking about this. fanpage \\u2014serving you the latest updates and old media of miss dilraba dilmurat also known as dilireba.\",\n",
      "      \"position\": 6\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"350 Dilireba ideas | chinese actress, actresses, asian girl - Pinterest\",\n",
      "      \"link\": \"https://www.pinterest.com/ffts25607/dilireba/\",\n",
      "      \"snippet\": \"Oct 10, 2018 - Explore SIN YEE's board \\\"dilireba\\\" on Pinterest. See more ideas about chinese actress, actresses, asian girl.\",\n",
      "      \"position\": 7\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"What's so special about dilraba? : r/CDrama - Reddit\",\n",
      "      \"link\": \"https://www.reddit.com/r/CDrama/comments/18w48it/whats_so_special_about_dilraba/\",\n",
      "      \"snippet\": \"1)She's an AMAZING actress 2)She has a good personality 3)She is beautiful 4) she's very kind and smart Dilreba is a very good actress and should be celebrated ...\",\n",
      "      \"date\": \"Jan 1, 2024\",\n",
      "      \"sitelinks\": [\n",
      "        {\n",
      "          \"title\": \"What are Chinese people's thought on dilraba dilmurat's look? - Reddit\",\n",
      "          \"link\": \"https://www.reddit.com/r/CDrama/comments/14q8bsl/what_are_chinese_peoples_thought_on_dilraba/\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Unpopular opinion: Dilireba was perfectly casted in The Long Ballad\",\n",
      "          \"link\": \"https://www.reddit.com/r/CDrama/comments/xc093m/unpopular_opinion_dilireba_was_perfectly_casted/\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Dilireba and Chen Xingxu upcoming drama boot ceremony : r/CDrama\",\n",
      "          \"link\": \"https://www.reddit.com/r/CDrama/comments/1bi9egy/dilireba_and_chen_xingxu_upcoming_drama_boot/\"\n",
      "        },\n",
      "        {\n",
      "          \"title\": \"Dilireba x Chen Xing Xu possible project together : r/CDrama - Reddit\",\n",
      "          \"link\": \"https://www.reddit.com/r/CDrama/comments/1avw7tm/dilireba_x_chen_xing_xu_possible_project_together/\"\n",
      "        }\n",
      "      ],\n",
      "      \"position\": 8\n",
      "    },\n",
      "    {\n",
      "      \"title\": \".Dilraba Dilmurat (@gemini6633) | TikTok\",\n",
      "      \"link\": \"https://www.tiktok.com/@gemini6633?lang=en\",\n",
      "      \"snippet\": \"Dilraba Dilmurat \\u2661 (@gemini6633) on TikTok | 17.6M Likes. 779K Followers. \\u2618\\ufe0fThanks for your like & follow\\u2728 you can call me Admin Meymey SG 13-06-21 .\",\n",
      "      \"position\": 9\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"254 Dilireba Stock Photos & High-Res Pictures - Getty Images\",\n",
      "      \"link\": \"https://www.gettyimages.com/photos/dilireba\",\n",
      "      \"snippet\": \"254 Dilireba Stock Photos & High-Res Pictures. Actress Dilraba Dilmurat attends Whisper Sanitary Pads commercial event on October 12, 2024 in Shanghai, China.\",\n",
      "      \"position\": 10\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Extracted Information: \n",
      "{'age': 31}\n",
      "Output dict:  {'age': 31}\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.evolnode import EvolNode\n",
    "from methods.llm import get_groq_response, get_claude_response\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Search for age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.CODE)\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "\n",
    "test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "test_inputs = [c[0] for c in test_cases]\n",
    "\n",
    "node = EvolNode(mp, None, None, get_response=get_endpoint_response, test_cases=test_cases) # setting manual test cases\n",
    "\n",
    "node.evolve(\"i1\", replace=True, batch_size=20, num_runs=2, print_summary=True) # Scale up batch size\n",
    "\n",
    "\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "node.get_response = get_groq_response # fast sequential inference \n",
    "output_dict = node(input_dict) # use node as a function\n",
    "print(\"Output dict: \", output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"img/Project-Nirvana-evolve.gif\" width=\"500\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Evolve a population of nodes. </em></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:16<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 16.98s, 0 errors\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m evo \u001b[38;5;241m=\u001b[39m Evolution(pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, meta_prompt\u001b[38;5;241m=\u001b[39mmp, get_response\u001b[38;5;241m=\u001b[39mget_endpoint_response, \n\u001b[1;32m     14\u001b[0m                 test_cases\u001b[38;5;241m=\u001b[39mtest_cases, max_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_eval_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     15\u001b[0m                 load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# [\"i1\", \"i1\", \"m2\", \"e2\"]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m evo\u001b[38;5;241m.\u001b[39mget_offspring(strategies)\n\u001b[1;32m     20\u001b[0m evo\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow effective is the current evolution strategy? What improvement has it made in terms of fitness, and in terms of the implementation?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m          get_claude_response) \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# code-based check \u001b[39;00m\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/population.py:152\u001b[0m, in \u001b[0;36mEvolution.get_offspring\u001b[0;34m(self, method, convert_to_plan)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(method, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m method:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_offspring(m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_plan \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan_threshold)):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverting to Plan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/population.py:109\u001b[0m, in \u001b[0;36mEvolution._get_offspring\u001b[0;34m(self, operator, pop, max_attempts)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pop) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPopulation size is less than the number of parents required for Mutation operator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     parents \u001b[38;5;241m=\u001b[39m parent_selection(pop, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# one parent used for mutation\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mevolve(operator, parents[\u001b[38;5;241m0\u001b[39m], replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39mmax_attempts, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_eval_runs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size)\n\u001b[1;32m    110\u001b[0m     offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m], offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m], offspring[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mreasoning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mcode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevol\u001b[38;5;241m.\u001b[39mfitness\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m#traditional GA\u001b[39;00m\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:462\u001b[0m, in \u001b[0;36mEvolNode.evolve\u001b[0;34m(self, method, parents, replace, feedback, batch_size, fitness_threshold, num_runs, max_tries, print_summary)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreasonings \u001b[38;5;241m=\u001b[39m reasonings\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes \u001b[38;5;241m=\u001b[39m codes\n\u001b[0;32m--> 462\u001b[0m fitness_per_code, errors_per_code, global_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_fitness(codes\u001b[38;5;241m=\u001b[39mcodes, max_tries\u001b[38;5;241m=\u001b[39mmax_tries, num_runs\u001b[38;5;241m=\u001b[39mnum_runs)\n\u001b[1;32m    463\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    464\u001b[0m evaluation_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m evolve_end_time\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:631\u001b[0m, in \u001b[0;36mEvolNode._evaluate_fitness\u001b[0;34m(self, test_cases, codes, max_tries, num_runs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     output_per_code_per_test, errors_per_code_per_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_code_function_parallel(test_inputs, codes)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_prompt\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m PromptMode\u001b[38;5;241m.\u001b[39mPROMPT:\n\u001b[0;32m--> 631\u001b[0m     output_per_code_per_test, errors_per_code_per_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_prompt_function_parallel(test_inputs, codes, max_tries)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_prompt\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:554\u001b[0m, in \u001b[0;36mEvolNode.call_prompt_function_parallel\u001b[0;34m(self, test_inputs, codes, max_tries)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_prompt_function_parallel\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_inputs: List[Dict], codes: Optional[List[\u001b[38;5;28mstr\u001b[39m]], max_tries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_func_prompt_parallel(test_inputs, codes, max_tries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_execute.py:197\u001b[0m, in \u001b[0;36mcall_func_prompt_parallel\u001b[0;34m(input_dicts, codes, max_tries, get_response)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m func_name \u001b[38;5;129;01min\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in code #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m prompt_func \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[func_name]\n\u001b[0;32m--> 197\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minput_dict)\n\u001b[1;32m    198\u001b[0m prompts\u001b[38;5;241m.\u001b[39mappend(prompt)\n\u001b[1;32m    199\u001b[0m input_indices\u001b[38;5;241m.\u001b[39mappend((input_index, code_index))\n",
      "File \u001b[0;32m<string>:55\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m<string>:55\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[0;34m(name)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: generate_prompt at line 55 (115 times)]\u001b[0m\n",
      "File \u001b[0;32m<string>:55\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m<string>:54\u001b[0m, in \u001b[0;36mgenerate_prompt\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m<string>:37\u001b[0m, in \u001b[0;36msearch_google\u001b[0;34m(query)\u001b[0m\n",
      "File \u001b[0;32m<string>:22\u001b[0m, in \u001b[0;36m_search_google\u001b[0;34m(query)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1284\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1456\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[1;32m   1459\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[1;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[1;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[1;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[1;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[1;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1106\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Population building phase ... \n",
    "from methods.llm import get_groq_response, get_claude_response\n",
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.population import Evolution\n",
    "\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "\n",
    "test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "evo = Evolution(pop_size=20, meta_prompt=mp, get_response=get_endpoint_response, \n",
    "                test_cases=test_cases, max_attempts=3, num_eval_runs=2,\n",
    "                load=True)\n",
    "\n",
    "strategies = [\"m2\"] # [\"i1\", \"i1\", \"m2\", \"e2\"]\n",
    "evo.get_offspring(strategies)\n",
    "\n",
    "evo.chat(\"How effective is the current evolution strategy? What improvement has it made in terms of fitness, and in terms of the implementation?\",\n",
    "         get_claude_response) \n",
    "\n",
    "# code-based check \n",
    "print(evo.population_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</div>\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/user-attachments/assets/af98faeb-66d6-4278-af86-67d668d1954e\" width=\"900\" alt=\"Fourier reconstruction convergence\">\n",
    "  <p><em> Plan, and evolve the plans. </em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Evolving 10 plans in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 21.45s, 0 errors\n",
      " :: Pseudo-code generated for each plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:24<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 24.02s, 0 errors\n",
      " :: Plan_dict generated for each plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "success: successfully compiled d2_output/plan_graph.d2 to d2_output/plan_graph.png in 126.367958ms\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:21<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 21.55s, 0 errors\n",
      "Spawned 3 test cases for all sub-nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_claude_response, get_groq_response\n",
    "from methods.diagram import visualize_plan_dict\n",
    "from methods.meta_prompt import MetaPlan\n",
    "from methods.evolnode import PlanNode\n",
    "\n",
    "\n",
    "# Initialize PlanNode \n",
    "mp = MetaPlan(\"Get the age of celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"])\n",
    "plan = PlanNode(mp, get_endpoint_response)\n",
    "\n",
    "# i1 evolution of plan\n",
    "plan_dicts, err_msg = plan.evolve_plan_dict(method=\"i1\", batch_size=10) # Batch_size of 100 gives no slow-down\n",
    "\n",
    "visualize_plan_dict(plan.plan_dict, plan.meta_prompt.task) # most simpliest plan\n",
    "\n",
    "# Manual input on main-node test cases \n",
    "main_test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "is_success, err_msg = plan.spawn_test_cases(main_test_cases) #  pinned test cases generation\n",
    "# plan.spawn_test_cases_majority(main_test_cases) # multi-agent test cases generation (need some benchmarking to compare quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ :: Evolving parse_birthdate ... (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:23<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 23.70s, 0 errors\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:38<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 38.94s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:03<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 3.87s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     node \u001b[38;5;241m=\u001b[39m EvolNode(meta_prompt, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, get_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response, test_cases\u001b[38;5;241m=\u001b[39mtest_cases)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müé≤ :: Evolving \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mmeta_prompt\u001b[38;5;241m.\u001b[39mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ... (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     node\u001b[38;5;241m.\u001b[39mevolve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi1\u001b[39m\u001b[38;5;124m\"\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \u001b[38;5;66;03m# It's funny how 30+ sec could elapse before llm inference ... (collecting prompts ?? wtf is taking so long ??)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:462\u001b[0m, in \u001b[0;36mEvolNode.evolve\u001b[0;34m(self, method, parents, replace, feedback, batch_size, fitness_threshold, num_runs, max_tries, print_summary)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreasonings \u001b[38;5;241m=\u001b[39m reasonings\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes \u001b[38;5;241m=\u001b[39m codes\n\u001b[0;32m--> 462\u001b[0m fitness_per_code, errors_per_code, global_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_fitness(codes\u001b[38;5;241m=\u001b[39mcodes, max_tries\u001b[38;5;241m=\u001b[39mmax_tries, num_runs\u001b[38;5;241m=\u001b[39mnum_runs)\n\u001b[1;32m    463\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    464\u001b[0m evaluation_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m evolve_end_time\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:639\u001b[0m, in \u001b[0;36mEvolNode._evaluate_fitness\u001b[0;34m(self, test_cases, codes, max_tries, num_runs)\u001b[0m\n\u001b[1;32m    637\u001b[0m test_inputs \u001b[38;5;241m=\u001b[39m [case[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m test_cases]\n\u001b[1;32m    638\u001b[0m target_outputs \u001b[38;5;241m=\u001b[39m [case[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m test_cases]\n\u001b[0;32m--> 639\u001b[0m score_per_code_per_test, evaluate_errors_per_code_per_test \u001b[38;5;241m=\u001b[39m check_alignment_parallel(output_per_code_per_test, test_inputs, target_outputs, \n\u001b[1;32m    640\u001b[0m                                                                                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response, batch_size\u001b[38;5;241m=\u001b[39mnum_runs)\n\u001b[1;32m    641\u001b[0m errors_per_code \u001b[38;5;241m=\u001b[39m combine_errors(evaluate_errors_per_code_per_test, errors_per_code_per_test)\n\u001b[1;32m    643\u001b[0m fitness_per_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize_fitness(codes, score_per_code_per_test, output_per_code_per_test, test_inputs, max_tries)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/evolnode.py:252\u001b[0m, in \u001b[0;36mcheck_alignment_parallel\u001b[0;34m(output_per_code_per_test, test_inputs, target_outputs, get_response, batch_size)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Get scores from LLM-based alignment check \u001b[39;00m\n\u001b[1;32m    249\u001b[0m llm_scores, errors_per_code_per_test \u001b[38;5;241m=\u001b[39m _check_alignment_with_llm_parallel(output_per_code_per_test, errors_per_code_per_test, test_inputs, target_outputs,\n\u001b[1;32m    250\u001b[0m                                                                           get_response, batch_size)\n\u001b[0;32m--> 252\u001b[0m score_per_code_per_test \u001b[38;5;241m=\u001b[39m combine_scores(llm_scores, metric_scores)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_per_code_per_test, errors_per_code_per_test\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_execute.py:412\u001b[0m, in \u001b[0;36mcombine_scores\u001b[0;34m(llm_scores, metric_scores)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m llm_scores: \n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m llm_scores[k]: \n\u001b[0;32m--> 412\u001b[0m         combined_scores[k][i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m llm_scores[k][i]\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m combined_scores: \n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m combined_scores[k]: \n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# plan.evolve_sub_nodes() # Completely stuck in the first call, debugging ... \n",
    "\n",
    "from methods.evolnode import EvolNode\n",
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "\n",
    "self = plan \n",
    "\n",
    "# 1. Did we skip existing nodes? Yes, those node has code & fitness and is skipped.\n",
    "# 2. Did we make the name compatible with slightly off input?\n",
    "\n",
    "for i, node_dict in enumerate(self.plan_dict[\"nodes\"]):\n",
    "    meta_prompt = MetaPrompt(\n",
    "        task=node_dict[\"task\"],\n",
    "        func_name=node_dict[\"name\"],\n",
    "        inputs=node_dict[\"inputs\"],\n",
    "        outputs=node_dict[\"outputs\"],\n",
    "        input_types=node_dict[\"input_types\"],\n",
    "        output_types=node_dict[\"output_types\"],\n",
    "        mode=PromptMode((node_dict.get(\"mode\", \"code\")).lower())\n",
    "    )\n",
    "    test_cases = self.test_cases_dict[node_dict[\"name\"]]\n",
    "    if \"fitness\" in node_dict and \"code\" in node_dict: \n",
    "        node = EvolNode(meta_prompt, node_dict[\"code\"], node_dict[\"reasoning\"], get_response=self.get_response, test_cases=test_cases, fitness=node_dict[\"fitness\"])\n",
    "    else:\n",
    "        node = EvolNode(meta_prompt, None, None, get_response=self.get_response, test_cases=test_cases)\n",
    "        print(f\"üé≤ :: Evolving {node.meta_prompt.func_name} ... ({i+1}/{len(self.plan_dict['nodes'])})\")\n",
    "        node.evolve(\"i1\", replace=True, max_tries=2, num_runs=2, batch_size=20) # It's funny how 30+ sec could elapse before llm inference ... (collecting prompts ?? wtf is taking so long ??)\n",
    "    self.nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:17<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 17.81s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:44<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 44.99s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No code block found in the response.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevolnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_evol_response, compile_code_with_references\n\u001b[1;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m responses[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m reasoning, code \u001b[38;5;241m=\u001b[39m parse_evol_response(response)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_prompt.py:265\u001b[0m, in \u001b[0;36mparse_evol_response\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         reasoning \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^.*?(?=def)\u001b[39m\u001b[38;5;124m'\u001b[39m, response, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[0;32m--> 265\u001b[0m code \u001b[38;5;241m=\u001b[39m extract_python_funcions(response)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_reasoning_str(reasoning[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m reasoning \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, code \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_prompt.py:846\u001b[0m, in \u001b[0;36mextract_python_funcions\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_python_funcions\u001b[39m(response: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    843\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;124;03m    Extract python snippet, use ast to extract functions and imports\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 846\u001b[0m     code_str \u001b[38;5;241m=\u001b[39m extract_python_code(response)\n\u001b[1;32m    847\u001b[0m     imports, functions \u001b[38;5;241m=\u001b[39m extract_imports_and_functions(code_str)\n\u001b[1;32m    848\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(imports \u001b[38;5;241m+\u001b[39m functions)\n",
      "File \u001b[0;32m~/Implementation/research/heuristic-search/eoh/methods/meta_prompt.py:821\u001b[0m, in \u001b[0;36mextract_python_code\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m code \n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo code block found in the response.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No code block found in the response."
     ]
    }
   ],
   "source": [
    "# node.evolve(method, replace=replace, max_tries=max_tries, num_runs=num_runs, batch_size=batch_size) # missing required input parameters: 'result' --> break down \n",
    "\n",
    "replace = True\n",
    "method = \"i1\"\n",
    "parents = []\n",
    "batch_size = 20\n",
    "num_runs = 2\n",
    "max_tries = 2\n",
    "self = node\n",
    "feedback = \"\"\n",
    "\n",
    "self.query_nodes(ignore_self=replace, self_func_name=self.meta_prompt.func_name) # look for relevant nodes in the library, go down\n",
    "\n",
    "reasonings, codes = self._evolve(method, parents, batch_size=batch_size) # Issue #2. duplicate relevant functions after compilation, go down \n",
    "\n",
    "responses = self._get_evolve_response(method, parents, feedback, batch_size)\n",
    "\n",
    "from methods.evolnode import parse_evol_response, compile_code_with_references\n",
    "\n",
    "response = responses[0]\n",
    "reasoning, code = parse_evol_response(response)\n",
    "# code = compile_code_with_references(code, self.referrable_function_dict) # deal with node references | go down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{To parse the Wikipedia page to extract the birthdate, we need to first identify the relevant section in the page, and then extract the birthdate information from that section. We will then generate a prompt to guide an AI in completing this task, specifying the input parameters, output format, and any additional requirements.}\n",
      "\n",
      "{Based on the given tools and their fitness, we will use the `get_celeb_age` function to get the age of a celebrity, but since we are looking for birthdate, we will use this function in a way that will help us get birthdate. We will also use `search_google` function to search for the Wikipedia page of the celebrity if we don't have their Wikipedia page.}\n",
      "\n",
      "def generate_prompt(wikipedia_page):\n",
      "    # If we have the Wikipedia page, we will use get_celeb_age function\n",
      "    if wikipedia_page:\n",
      "        prompt = f\"Given the Wikipedia page {{input: {wikipedia_page}}}, do extract the birthdate from the 'Early Life' section. Make sure the output is a json string in markdown like this {{birthdate: <value>}}.\"\n",
      "    else:\n",
      "        # If we don't have the Wikipedia page, we will search for it using google\n",
      "        search_result = search_google(\"Wikipedia page of \" + wikipedia_page)\n",
      "        # We will then use the get_celeb_age function to get the birthdate\n",
      "        prompt = f\"Given the search result {{input: {search_result}}}, do extract the birthdate from the 'Early Life' section. Make sure the output is a json string in markdown like this {{birthdate: <value>}}.\"\n",
      "    return prompt\n",
      "\n",
      "# We will use the get_celeb_age function to get the birthdate\n",
      "def get_celeb_birthdate(name):\n",
      "    age = get_celeb_age(name)\n",
      "    current_year = 2023\n",
      "    birthdate = str(current_year - int(age))\n",
      "    return birthdate\n",
      "\n",
      "# Example usage:\n",
      "wikipedia_page = \"Turing Award winner\"\n",
      "prompt = generate_prompt(wikipedia_page)\n",
      "print(prompt)\n",
      "\n",
      "# The AI will respond with a json string in markdown like this:\n",
      "# {{birthdate: <value>}}\n",
      "# We will then use the get_celeb_birthdate function to get the birthdate and print it\n",
      "ai_response = \"{'birthdate': '1950'}\"\n",
      "birthdate = get_celeb_birthdate(\"Turing Award winner\")\n",
      "print(f\"Birthdate: {birthdate}\")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from datetime import datetime\n",
      "from dateutil.relativedelta import relativedelta\n",
      "from typing import Optional\n",
      "def search_google(query: str) -> str:\n",
      "    pass\n",
      "def get_celeb_age(name: str) -> Optional[int]:\n",
      "    pass\n",
      "def parse_result(result: str) -> Optional[int]:\n",
      "    \"\"\"\n",
      "    Parse the search result to extract the age of a celebrity.\n",
      "\n",
      "    Args:\n",
      "        result (str): The search result as a string.\n",
      "\n",
      "    Returns:\n",
      "        Optional[int]: The celebrity's age as an integer or None if not found.\n",
      "    \"\"\"\n",
      "    search_result = search_google(name + ' birth date')\n",
      "    birth_date_str = None\n",
      "    for line in search_result.split('\\n'):\n",
      "        if 'birth date' in line.lower():\n",
      "            birth_date_str = line.split(': ')[1]\n",
      "            break\n",
      "    if birth_date_str:\n",
      "        birth_date = datetime.strptime(birth_date_str, '%B %d, %Y')\n",
      "        current_year = datetime.now().year\n",
      "        age = relativedelta(current_year, birth_date.year).years\n",
      "        return age\n",
      "    else:\n",
      "        age_str = get_celeb_age(name)\n",
      "        if age_str is not None:\n",
      "            return age_str\n",
      "    return None\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
