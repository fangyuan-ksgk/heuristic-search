{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_async_vllm_endpoint\n",
    "import os \n",
    "\n",
    "# Unlimited LLM endpoints\n",
    "endpoint_id = \"vllm-8sz1f7zg7oy0ui\"\n",
    "api_key = \"rpa_EPOJED42G59S80Y6SKMCOI330EQU4JPPMKV2UD2W7j0uku\"\n",
    "get_endpoint_response = get_async_vllm_endpoint(endpoint_id, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temasek Foundation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Test cases (dataloading ...)\n",
    "import sys \n",
    "sys.path.append(\"../notebook/\")\n",
    "from optm.soft_prompt import load_tf_data\n",
    "\n",
    "train_data, test_data = load_tf_data(\"../data/processed_data_clean.json\")\n",
    "\n",
    "# reference metric fuction below ... we care about prediction of label, specifically \"no\"\n",
    "# we care about precision more than we care abou recall on 'No' prediction \n",
    "\n",
    "# Node dataset should ideally be concise and pure application info included ...\n",
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "\n",
    "tf_meta_prompt = MetaPrompt(\n",
    "    task = \"Evaluate grant application, make a decision (Yes, No, Maybe) and a brief comment explanating your decision on why this project is likely to be accepted or rejected.\",\n",
    "    func_name = \"evaluate_grant\",\n",
    "    inputs = [\"project_description\"],\n",
    "    outputs = [\"label\", \"comment\"],\n",
    "    input_types = [\"str\"],\n",
    "    output_types = [\"str\", \"str\"],\n",
    "    mode = PromptMode.PROMPT\n",
    ")\n",
    "\n",
    "# Prepare test cases :: input dict & output dict\n",
    "test_cases = []\n",
    "for prompt, label, comment in zip(train_data[\"prompt\"], train_data[\"label\"], train_data[\"comment\"]):\n",
    "    test_cases.append(({\"project_description\": prompt}, {\"label\": label, \"comment\": comment}))\n",
    "    \n",
    "\n",
    "# Specific Metric required for TF dataset (Worth refactor the code a bit)\n",
    "from methods.evolnode import EvolNode \n",
    "node = EvolNode(tf_meta_prompt, None, None, get_response=get_endpoint_response, test_cases=test_cases,\n",
    "                custom_metric_map=None) # setting manual test cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = test_cases[0][1]\n",
    "pred_dict = test_cases[1][1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric works on output dictionary, both element level and batch level (indiv score & overall score)\n",
    "\n",
    "from typing import Union, Callable\n",
    "\n",
    "def tf_name_to_metric(output_name: str) -> Callable: \n",
    "    \"\"\" \n",
    "    Dataset specific metric pointer\n",
    "    \"\"\"\n",
    "    if output_name == \"label\":\n",
    "        return tf_label_metric\n",
    "    else:\n",
    "        raise ValueError(f\"No metric for output: {output_name}\")\n",
    "\n",
    "def tf_label_metric(target_outputs: Union[list, dict], pred_outputs: Union[list, dict],\n",
    "                    beta: float = 5):\n",
    "    \"\"\" \n",
    "    \"No\" prediction > \"Yes\" prediction \n",
    "    Recall > Precision\n",
    "    Weighted score (recall + precision) with beta : 1 as weights \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(target_outputs, dict):\n",
    "        target_outputs = [target_outputs]\n",
    "    if isinstance(pred_outputs, dict):\n",
    "        pred_outputs = [pred_outputs]\n",
    "        \n",
    "    assert all(\"label\" in target and \"comment\" in target for target in target_outputs), \"Target outputs must contain 'label' and 'comment'\"\n",
    "    assert all(\"label\" in pred and \"comment\" in pred for pred in pred_outputs), \"Predicted outputs must contain 'label' and 'comment'\"\n",
    "    \n",
    "    # Extract labels\n",
    "    true_labels = [t[\"label\"].lower().strip() for t in target_outputs]\n",
    "    pred_labels = [p[\"label\"].lower().strip() for p in pred_outputs]\n",
    "    \n",
    "    # Calculate metrics for \"no\" predictions\n",
    "    true_no = sum(1 for label in true_labels if label == \"no\")\n",
    "    pred_no = sum(1 for label in pred_labels if label == \"no\")\n",
    "    true_pos_no = sum(1 for t, p in zip(true_labels, pred_labels) if t == \"no\" and p == \"no\")\n",
    "    \n",
    "    # Calculate precision and recall for \"no\"\n",
    "    no_precision = true_pos_no / pred_no if pred_no > 0 else 0\n",
    "    no_recall = true_pos_no / true_no if true_no > 0 else 0\n",
    "    \n",
    "    # Calculate precision and recall for \"no\"\n",
    "    no_precision = true_pos_no / pred_no if pred_no > 0 else 0\n",
    "    no_recall = true_pos_no / true_no if true_no > 0 else 0\n",
    "    \n",
    "    # Simple weighted score using beta\n",
    "    beta = 5  # Keeping your beta parameter\n",
    "    weighted_score = ((1 / (1 + beta)) * no_precision + (beta / (1 + beta)) * no_recall) if (no_precision + no_recall) > 0 else 0.0\n",
    "    \n",
    "    return weighted_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf_meta_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:10<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 10.15s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:25<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 25.63s, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM queries: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :: Total time elapsed: 0.00s, 0 errors\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.33\n",
      "  üéØ Functional fitness: 1.00\n",
      "  ‚≠ê Global fitness:     0.67\n",
      "  üîÑ Compiled solutions:        17\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 33.43s\n",
      "     :: Evolution time: 10.19s\n",
      "     :: Evaluation time: 55.46s\n",
      "     :: Total time: 99.09s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 're' is not defined\n",
      "name 're' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 66.7%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 3: Fitness: 66.7%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 4: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 5: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 6: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'results': [{'name': 'Dilireba', 'age': 32, ' occupation': 'Actress'}, {'name': 'Other Person', 'age': 25, ' occupation': 'Engineer'}]}, Error message: Key age not found in prediction output\n",
      "\n",
      "\n",
      "'NoneType' object has no attribute 'group'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 7: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- No JSON structure found in the provided text.\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 8: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "string indices must be integers, not 'str'\n",
      "string indices must be integers, not 'str'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 9: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'age': None}, Error message: Value None can't be converted into integer\n",
      "Value mismatch for key age: None != 32\n",
      "\n",
      "\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 10: Fitness: 66.7%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 11: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 12: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- No JSON structure found in the provided text.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 13: Fitness: 33.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 14: Fitness: 8.3%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'name': 'Dilireba'}, prediction is not aligned with expected output, Expected: {'age': 32} Predicted: {'age': 30}, Error message: \n",
      "Value mismatch for key age: 30 != 32\n",
      "\n",
      "\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 15: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "Failed to parse LLM response -- JsonDecodeError : \n",
      "Expecting value: line 1 column 1 (char 0)AstLiteralError : \n",
      "invalid syntax (<unknown>, line 1)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 16: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Failed to parse LLM response -- No JSON structure found in the provided text.\n",
      "Failed to parse LLM response -- No JSON structure found in the provided text.\n",
      "================================================================================\n",
      "\n",
      "Error occurred during API request: Function execution timed out (> 3 seconds)\n"
     ]
    }
   ],
   "source": [
    "from methods.meta_prompt import MetaPrompt, PromptMode\n",
    "from methods.evolnode import EvolNode\n",
    "from methods.llm import get_groq_response, get_claude_response\n",
    "\n",
    "# Code + Compilor Task\n",
    "# mp = MetaPrompt(\"Search for age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.CODE)\n",
    "# Prompt + LLM Task\n",
    "mp = MetaPrompt(\"Get the age of a celebrity.\", \"get_celeb_age\", [\"name\"], [\"age\"], [\"str\"], [\"int\"], PromptMode.PROMPT) # \n",
    "\n",
    "test_cases = [\n",
    "    ({\"name\": \"Dilireba\"}, {\"age\": 32}),\n",
    "    ({\"name\": \"ChengXiao\"}, {\"age\": 26})\n",
    "]\n",
    "\n",
    "test_inputs = [c[0] for c in test_cases]\n",
    "\n",
    "node = EvolNode(mp, None, None, get_response=get_endpoint_response, test_cases=test_cases) # setting manual test cases\n",
    "\n",
    "node.evolve(\"i1\", replace=True, batch_size=20, num_runs=2, print_summary=True) # Scale up batch size\n",
    "\n",
    "\n",
    "input_dict = {\"name\": \"Dilireba\"}\n",
    "output_dict = node(input_dict, max_attempts=6) # Batch Inference with vLLM\n",
    "\n",
    "# node.get_response = get_groq_response # fast sequential inference\n",
    "# output_dict = node(input_dict, max_attempts=6, batch_inference=False)\n",
    " \n",
    "print(\"Output dict: \", output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
